{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a17fbd2",
      "metadata": {
        "id": "9a17fbd2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
        "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('always')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9ea3b4",
      "metadata": {
        "id": "ac9ea3b4"
      },
      "outputs": [],
      "source": [
        "# Importación librerías\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8da0ef1",
      "metadata": {
        "id": "a8da0ef1"
      },
      "outputs": [],
      "source": [
        "# Carga de datos de archivo .csv\n",
        "dataTraining = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTrain_carListings.zip')\n",
        "dataTesting = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTest_carListings.zip', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a489df",
      "metadata": {
        "id": "b6a489df",
        "outputId": "21ebfc4e-ac10-4dc6-bbd6-73bae95d65d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>State</th>\n",
              "      <th>Make</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34995</td>\n",
              "      <td>2017</td>\n",
              "      <td>9913</td>\n",
              "      <td>FL</td>\n",
              "      <td>Jeep</td>\n",
              "      <td>Wrangler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37895</td>\n",
              "      <td>2015</td>\n",
              "      <td>20578</td>\n",
              "      <td>OH</td>\n",
              "      <td>Chevrolet</td>\n",
              "      <td>Tahoe4WD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18430</td>\n",
              "      <td>2012</td>\n",
              "      <td>83716</td>\n",
              "      <td>TX</td>\n",
              "      <td>BMW</td>\n",
              "      <td>X5AWD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24681</td>\n",
              "      <td>2014</td>\n",
              "      <td>28729</td>\n",
              "      <td>OH</td>\n",
              "      <td>Cadillac</td>\n",
              "      <td>SRXLuxury</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26998</td>\n",
              "      <td>2013</td>\n",
              "      <td>64032</td>\n",
              "      <td>CO</td>\n",
              "      <td>Jeep</td>\n",
              "      <td>Wrangler</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Price  Year  Mileage State       Make      Model\n",
              "0  34995  2017     9913    FL       Jeep   Wrangler\n",
              "1  37895  2015    20578    OH  Chevrolet   Tahoe4WD\n",
              "2  18430  2012    83716    TX        BMW      X5AWD\n",
              "3  24681  2014    28729    OH   Cadillac  SRXLuxury\n",
              "4  26998  2013    64032    CO       Jeep   Wrangler"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualización datos de entrenamiento\n",
        "dataTraining.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c7d270",
      "metadata": {
        "id": "e4c7d270"
      },
      "source": [
        "Dataset\n",
        "\n",
        "Los automóviles tienen un precio inicial establecido por el fabricante, a medida que estos vehículos envejecen y se venden como usados, su valor se determina por la oferta y la demanda, así como por su historial único. Cuanto más se diferencien estos autos de otros similares, más difícil será evaluar su precio utilizando métodos tradicionales. Sin embargo, el uso de algoritmos de aprendizaje automático puede ayudarnos a evaluar con mayor precisión el valor de un vehículo al considerar todas las características:\n",
        "\n",
        "\n",
        "\n",
        "Price: precio del vehiculo usado\n",
        "\n",
        "Year: año de fabricacion, salida al mercado\n",
        "\n",
        "Mileage: millas recorridas (kilometraje)\n",
        "\n",
        "Make: marca del fabricante\n",
        "\n",
        "Model: modelo de vehiculo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb65457",
      "metadata": {
        "id": "7fb65457",
        "outputId": "257adeaf-d099-4d27-b9c8-528459215e3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Price      0\n",
              "Year       0\n",
              "Mileage    0\n",
              "State      0\n",
              "Make       0\n",
              "Model      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#verificacion de datos faltantes\n",
        "valores_nulos_por_columna = dataTraining.isnull().sum()\n",
        "valores_nulos_por_columna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f8839bf",
      "metadata": {
        "id": "3f8839bf"
      },
      "source": [
        "No se registran datos faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5457dec5",
      "metadata": {
        "id": "5457dec5",
        "outputId": "7e28740d-2f83-4d45-86c2-1f00fb54d623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price       int64\n",
            "Year        int64\n",
            "Mileage     int64\n",
            "State      object\n",
            "Make       object\n",
            "Model      object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# tipos de datos\n",
        "\n",
        "\n",
        "tipos=dataTraining.dtypes\n",
        "print(tipos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac74ff30",
      "metadata": {
        "id": "ac74ff30"
      },
      "source": [
        "Se tienen 3 caracteristicas numericas y 3 categoricas, verifiquemos la cantidad de clases de cada categoria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78454292",
      "metadata": {
        "id": "78454292",
        "outputId": "60d5b49a-988a-4bbb-b3c1-104bad7950df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "State\n",
              " TX    45918\n",
              " CA    36534\n",
              " FL    33759\n",
              " GA    18182\n",
              " NC    17930\n",
              " IL    16793\n",
              " VA    15894\n",
              " PA    13039\n",
              " NY    12447\n",
              " NJ    12132\n",
              " OH    11364\n",
              " WA    10900\n",
              " CO    10875\n",
              " AZ    10749\n",
              " TN     9274\n",
              " MA     8586\n",
              " MD     8245\n",
              " MO     8029\n",
              " IN     7850\n",
              " KY     6688\n",
              " AL     6283\n",
              " WI     5614\n",
              " MN     5415\n",
              " MI     5327\n",
              " OK     5096\n",
              " CT     4942\n",
              " OR     4907\n",
              " UT     4854\n",
              " SC     4815\n",
              " LA     3847\n",
              " KS     3704\n",
              " NV     3332\n",
              " AR     3128\n",
              " MS     3043\n",
              " NH     2744\n",
              " NE     2522\n",
              " IA     2325\n",
              " NM     2280\n",
              " ID     1736\n",
              " DE     1221\n",
              " HI     1181\n",
              " MT      997\n",
              " ME      965\n",
              " RI      833\n",
              " AK      813\n",
              " ND      681\n",
              " WV      666\n",
              " SD      621\n",
              " VT      579\n",
              " WY      335\n",
              " DC        6\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#conteo de datos categoricos:\n",
        "#conteo de categorias en la variable Class\n",
        "conteostate = dataTraining['State'].value_counts()\n",
        "\n",
        "display(conteostate)\n",
        "len(conteostate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a185300a",
      "metadata": {
        "id": "a185300a"
      },
      "source": [
        "Los Estados Unidos tienen 50 estados, 1 distrito federal, 5 territorios importantes, y 9 territorios menores, el anterior listado hace referencia a sus 50 estados y su distrito federal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041d9dd0",
      "metadata": {
        "id": "041d9dd0",
        "outputId": "613cad9e-f860-4dcc-e64b-82a695b37457"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Make\n",
              "Ford             62899\n",
              "Chevrolet        58383\n",
              "Toyota           45941\n",
              "Honda            33191\n",
              "Jeep             24369\n",
              "GMC              20834\n",
              "Kia              16352\n",
              "Dodge            16159\n",
              "Hyundai          15057\n",
              "Lexus            13664\n",
              "BMW              12326\n",
              "Volkswagen       11110\n",
              "Nissan           10569\n",
              "Chrysler          9046\n",
              "Mercedes-Benz     7575\n",
              "Subaru            6791\n",
              "Cadillac          5414\n",
              "Buick             4842\n",
              "Ram               3611\n",
              "MINI              2766\n",
              "Land              2713\n",
              "INFINITI          2406\n",
              "Acura             2403\n",
              "Mazda             2332\n",
              "Lincoln           1786\n",
              "Volvo             1710\n",
              "Audi              1423\n",
              "Mitsubishi        1272\n",
              "Porsche            980\n",
              "Scion              651\n",
              "Jaguar             324\n",
              "Pontiac            308\n",
              "FIAT               272\n",
              "Mercury            271\n",
              "Tesla              148\n",
              "Bentley             57\n",
              "Suzuki              38\n",
              "Freightliner         7\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#conteo de datos categoricos:\n",
        "\n",
        "conteoMake = dataTraining['Make'].value_counts()\n",
        "\n",
        "display(conteoMake)\n",
        "len(conteoMake)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be03b814",
      "metadata": {
        "id": "be03b814"
      },
      "source": [
        "Son 38 diferentes marcas o fabricantes del vehiculo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c546db57",
      "metadata": {
        "id": "c546db57",
        "outputId": "5760215e-334d-4183-df5c-4244d03ed506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model\n",
              "Silverado          18085\n",
              "Grand              12344\n",
              "Sierra              8409\n",
              "Accord              7357\n",
              "F-1504WD            6684\n",
              "                   ...  \n",
              "PathfinderSE          53\n",
              "Galant4dr             53\n",
              "SLK-ClassSLK350       52\n",
              "Monte                 48\n",
              "RX-84dr               48\n",
              "Name: count, Length: 525, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#conteo de datos categoricos:\n",
        "\n",
        "conteoModel = dataTraining['Model'].value_counts()\n",
        "\n",
        "display(conteoModel)\n",
        "len(conteoModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a641630",
      "metadata": {
        "id": "1a641630"
      },
      "source": [
        "Existen 525 diferentes tipos de modelos de vehiculos\n",
        "\n",
        "Para tratar estos datos se realizara dummy y se eliminaran las variables categoricas originales, en total quedaran 617 variables binarias para dataTraining donde 1 quiere decir que si pertenece y cero que no. tambien, se tratara igual en conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8dfff4",
      "metadata": {
        "id": "af8dfff4"
      },
      "outputs": [],
      "source": [
        "#dummies\n",
        "dataTraining = dataTraining.join(pd.get_dummies(dataTraining['Model'], prefix='M'))\n",
        "dataTesting = dataTesting.join(pd.get_dummies(dataTesting['Model'], prefix='M'))\n",
        "dataTraining = dataTraining.join(pd.get_dummies(dataTraining['Make'], prefix='K'))\n",
        "dataTesting = dataTesting.join(pd.get_dummies(dataTesting['Make'], prefix='K'))\n",
        "dataTraining = dataTraining.join(pd.get_dummies(dataTraining['State'], prefix='S'))\n",
        "dataTesting = dataTesting.join(pd.get_dummies(dataTesting['State'], prefix='S'))\n",
        "dataTraining = dataTraining.drop(['Model'], axis=1)\n",
        "dataTesting = dataTesting.drop(['Model'], axis=1)\n",
        "dataTraining = dataTraining.drop(['Make'], axis=1)\n",
        "dataTesting = dataTesting.drop(['Make'], axis=1)\n",
        "dataTraining = dataTraining.drop(['State'], axis=1)\n",
        "dataTesting = dataTesting.drop(['State'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a1f9ff",
      "metadata": {
        "id": "d9a1f9ff",
        "outputId": "e64e9d19-c94f-4979-f858-d6b68595b3bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>...</th>\n",
              "      <th>S_ SD</th>\n",
              "      <th>S_ TN</th>\n",
              "      <th>S_ TX</th>\n",
              "      <th>S_ UT</th>\n",
              "      <th>S_ VA</th>\n",
              "      <th>S_ VT</th>\n",
              "      <th>S_ WA</th>\n",
              "      <th>S_ WI</th>\n",
              "      <th>S_ WV</th>\n",
              "      <th>S_ WY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34995</td>\n",
              "      <td>2017</td>\n",
              "      <td>9913</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37895</td>\n",
              "      <td>2015</td>\n",
              "      <td>20578</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18430</td>\n",
              "      <td>2012</td>\n",
              "      <td>83716</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24681</td>\n",
              "      <td>2014</td>\n",
              "      <td>28729</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26998</td>\n",
              "      <td>2013</td>\n",
              "      <td>64032</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 617 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Price  Year  Mileage    M_1  M_15002WD  M_15004WD  M_1500Laramie  \\\n",
              "0  34995  2017     9913  False      False      False          False   \n",
              "1  37895  2015    20578  False      False      False          False   \n",
              "2  18430  2012    83716  False      False      False          False   \n",
              "3  24681  2014    28729  False      False      False          False   \n",
              "4  26998  2013    64032  False      False      False          False   \n",
              "\n",
              "   M_1500Tradesman  M_200LX  M_200Limited  ...  S_ SD  S_ TN  S_ TX  S_ UT  \\\n",
              "0            False    False         False  ...  False  False  False  False   \n",
              "1            False    False         False  ...  False  False  False  False   \n",
              "2            False    False         False  ...  False  False   True  False   \n",
              "3            False    False         False  ...  False  False  False  False   \n",
              "4            False    False         False  ...  False  False  False  False   \n",
              "\n",
              "   S_ VA  S_ VT  S_ WA  S_ WI  S_ WV  S_ WY  \n",
              "0  False  False  False  False  False  False  \n",
              "1  False  False  False  False  False  False  \n",
              "2  False  False  False  False  False  False  \n",
              "3  False  False  False  False  False  False  \n",
              "4  False  False  False  False  False  False  \n",
              "\n",
              "[5 rows x 617 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataTraining.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67245300",
      "metadata": {
        "id": "67245300",
        "outputId": "b3c83eb5-4f10-4fd9-e21d-928622444a5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>...</th>\n",
              "      <th>S_ SD</th>\n",
              "      <th>S_ TN</th>\n",
              "      <th>S_ TX</th>\n",
              "      <th>S_ UT</th>\n",
              "      <th>S_ VA</th>\n",
              "      <th>S_ VT</th>\n",
              "      <th>S_ WA</th>\n",
              "      <th>S_ WI</th>\n",
              "      <th>S_ WV</th>\n",
              "      <th>S_ WY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34995</td>\n",
              "      <td>2017</td>\n",
              "      <td>9913</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37895</td>\n",
              "      <td>2015</td>\n",
              "      <td>20578</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18430</td>\n",
              "      <td>2012</td>\n",
              "      <td>83716</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24681</td>\n",
              "      <td>2014</td>\n",
              "      <td>28729</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26998</td>\n",
              "      <td>2013</td>\n",
              "      <td>64032</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 617 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Price  Year  Mileage  M_1  M_15002WD  M_15004WD  M_1500Laramie  \\\n",
              "0  34995  2017     9913    0          0          0              0   \n",
              "1  37895  2015    20578    0          0          0              0   \n",
              "2  18430  2012    83716    0          0          0              0   \n",
              "3  24681  2014    28729    0          0          0              0   \n",
              "4  26998  2013    64032    0          0          0              0   \n",
              "\n",
              "   M_1500Tradesman  M_200LX  M_200Limited  ...  S_ SD  S_ TN  S_ TX  S_ UT  \\\n",
              "0                0        0             0  ...      0      0      0      0   \n",
              "1                0        0             0  ...      0      0      0      0   \n",
              "2                0        0             0  ...      0      0      1      0   \n",
              "3                0        0             0  ...      0      0      0      0   \n",
              "4                0        0             0  ...      0      0      0      0   \n",
              "\n",
              "   S_ VA  S_ VT  S_ WA  S_ WI  S_ WV  S_ WY  \n",
              "0      0      0      0      0      0      0  \n",
              "1      0      0      0      0      0      0  \n",
              "2      0      0      0      0      0      0  \n",
              "3      0      0      0      0      0      0  \n",
              "4      0      0      0      0      0      0  \n",
              "\n",
              "[5 rows x 617 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>M_200S</th>\n",
              "      <th>...</th>\n",
              "      <th>S_ SD</th>\n",
              "      <th>S_ TN</th>\n",
              "      <th>S_ TX</th>\n",
              "      <th>S_ UT</th>\n",
              "      <th>S_ VA</th>\n",
              "      <th>S_ VT</th>\n",
              "      <th>S_ WA</th>\n",
              "      <th>S_ WI</th>\n",
              "      <th>S_ WV</th>\n",
              "      <th>S_ WY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014</td>\n",
              "      <td>31909</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017</td>\n",
              "      <td>5362</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014</td>\n",
              "      <td>50300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004</td>\n",
              "      <td>132160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>25226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 615 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Year  Mileage  M_1  M_15002WD  M_15004WD  M_1500Laramie  M_1500Tradesman  \\\n",
              "ID                                                                             \n",
              "0   2014    31909    0          0          0              0                0   \n",
              "1   2017     5362    0          0          0              0                0   \n",
              "2   2014    50300    0          0          0              0                0   \n",
              "3   2004   132160    0          0          0              0                0   \n",
              "4   2015    25226    0          0          0              0                0   \n",
              "\n",
              "    M_200LX  M_200Limited  M_200S  ...  S_ SD  S_ TN  S_ TX  S_ UT  S_ VA  \\\n",
              "ID                                 ...                                      \n",
              "0         0             0       0  ...      0      0      0      0      0   \n",
              "1         0             0       0  ...      0      0      0      0      0   \n",
              "2         0             0       0  ...      0      0      0      0      0   \n",
              "3         0             0       0  ...      0      0      0      0      0   \n",
              "4         0             0       0  ...      0      0      0      0      0   \n",
              "\n",
              "    S_ VT  S_ WA  S_ WI  S_ WV  S_ WY  \n",
              "ID                                     \n",
              "0       0      0      0      0      0  \n",
              "1       0      0      0      0      0  \n",
              "2       0      0      0      0      0  \n",
              "3       0      1      0      0      0  \n",
              "4       0      0      0      0      0  \n",
              "\n",
              "[5 rows x 615 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Binaria\n",
        "dataTraining = dataTraining.astype(int)\n",
        "dataTesting= dataTesting.astype(int)\n",
        "display(dataTraining.head())\n",
        "display(dataTesting.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c048e08",
      "metadata": {
        "id": "7c048e08"
      },
      "source": [
        "Se nota que una diferencia de 2 entre entrentamiento y test cuando deberia ser solo una, el precio, se procede a verificar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7700e8a5",
      "metadata": {
        "id": "7700e8a5",
        "outputId": "f8e16b63-3884-4085-bf64-9c22dcdf46ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas en dataTraining que no están en dataTesting:\n",
            "['Price', 'K_Freightliner']\n"
          ]
        }
      ],
      "source": [
        "#comparativo\n",
        "\n",
        "columnasTr=dataTraining.columns\n",
        "columnasTs=dataTesting.columns\n",
        "\n",
        "columnas_no_encontradas = []\n",
        "\n",
        "for columna in columnasTr:\n",
        "    if columna not in columnasTs:\n",
        "        columnas_no_encontradas.append(columna)\n",
        "\n",
        "print(\"Columnas en dataTraining que no están en dataTesting:\")\n",
        "print(columnas_no_encontradas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda486a6",
      "metadata": {
        "id": "fda486a6"
      },
      "source": [
        "A este punto en pro de mantener la consistencia entre dataTraining y dataTesting se eliminará la columna \"K_Freightliner\" del conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc275543",
      "metadata": {
        "id": "dc275543",
        "outputId": "3328ef7a-089c-4923-8e67-b77c6e251aa0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>...</th>\n",
              "      <th>S_ SD</th>\n",
              "      <th>S_ TN</th>\n",
              "      <th>S_ TX</th>\n",
              "      <th>S_ UT</th>\n",
              "      <th>S_ VA</th>\n",
              "      <th>S_ VT</th>\n",
              "      <th>S_ WA</th>\n",
              "      <th>S_ WI</th>\n",
              "      <th>S_ WV</th>\n",
              "      <th>S_ WY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34995</td>\n",
              "      <td>2017</td>\n",
              "      <td>9913</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37895</td>\n",
              "      <td>2015</td>\n",
              "      <td>20578</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18430</td>\n",
              "      <td>2012</td>\n",
              "      <td>83716</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24681</td>\n",
              "      <td>2014</td>\n",
              "      <td>28729</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26998</td>\n",
              "      <td>2013</td>\n",
              "      <td>64032</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399995</th>\n",
              "      <td>29900</td>\n",
              "      <td>2015</td>\n",
              "      <td>25287</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399996</th>\n",
              "      <td>17688</td>\n",
              "      <td>2015</td>\n",
              "      <td>17677</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399997</th>\n",
              "      <td>24907</td>\n",
              "      <td>2014</td>\n",
              "      <td>66688</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399998</th>\n",
              "      <td>11498</td>\n",
              "      <td>2014</td>\n",
              "      <td>37872</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399999</th>\n",
              "      <td>16900</td>\n",
              "      <td>2014</td>\n",
              "      <td>78606</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 616 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Price  Year  Mileage  M_1  M_15002WD  M_15004WD  M_1500Laramie  \\\n",
              "0       34995  2017     9913    0          0          0              0   \n",
              "1       37895  2015    20578    0          0          0              0   \n",
              "2       18430  2012    83716    0          0          0              0   \n",
              "3       24681  2014    28729    0          0          0              0   \n",
              "4       26998  2013    64032    0          0          0              0   \n",
              "...       ...   ...      ...  ...        ...        ...            ...   \n",
              "399995  29900  2015    25287    0          0          0              0   \n",
              "399996  17688  2015    17677    0          0          0              0   \n",
              "399997  24907  2014    66688    0          0          0              0   \n",
              "399998  11498  2014    37872    0          0          0              0   \n",
              "399999  16900  2014    78606    0          0          0              0   \n",
              "\n",
              "        M_1500Tradesman  M_200LX  M_200Limited  ...  S_ SD  S_ TN  S_ TX  \\\n",
              "0                     0        0             0  ...      0      0      0   \n",
              "1                     0        0             0  ...      0      0      0   \n",
              "2                     0        0             0  ...      0      0      1   \n",
              "3                     0        0             0  ...      0      0      0   \n",
              "4                     0        0             0  ...      0      0      0   \n",
              "...                 ...      ...           ...  ...    ...    ...    ...   \n",
              "399995                0        0             0  ...      0      0      1   \n",
              "399996                0        0             0  ...      0      0      0   \n",
              "399997                0        0             0  ...      0      0      0   \n",
              "399998                0        0             0  ...      0      0      0   \n",
              "399999                0        0             0  ...      0      0      0   \n",
              "\n",
              "        S_ UT  S_ VA  S_ VT  S_ WA  S_ WI  S_ WV  S_ WY  \n",
              "0           0      0      0      0      0      0      0  \n",
              "1           0      0      0      0      0      0      0  \n",
              "2           0      0      0      0      0      0      0  \n",
              "3           0      0      0      0      0      0      0  \n",
              "4           0      0      0      0      0      0      0  \n",
              "...       ...    ...    ...    ...    ...    ...    ...  \n",
              "399995      0      0      0      0      0      0      0  \n",
              "399996      0      0      0      0      0      0      0  \n",
              "399997      0      0      0      0      0      0      0  \n",
              "399998      0      0      0      0      0      0      0  \n",
              "399999      0      0      0      0      0      0      0  \n",
              "\n",
              "[400000 rows x 616 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataTraining = dataTraining.drop(['K_Freightliner'], axis=1)\n",
        "dataTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545c6580",
      "metadata": {
        "id": "545c6580",
        "outputId": "3d1d2e31-a20c-4965-afe9-a63bc966d0c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>...</th>\n",
              "      <th>S__SD</th>\n",
              "      <th>S__TN</th>\n",
              "      <th>S__TX</th>\n",
              "      <th>S__UT</th>\n",
              "      <th>S__VA</th>\n",
              "      <th>S__VT</th>\n",
              "      <th>S__WA</th>\n",
              "      <th>S__WI</th>\n",
              "      <th>S__WV</th>\n",
              "      <th>S__WY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34995</td>\n",
              "      <td>2017</td>\n",
              "      <td>9913</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37895</td>\n",
              "      <td>2015</td>\n",
              "      <td>20578</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18430</td>\n",
              "      <td>2012</td>\n",
              "      <td>83716</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24681</td>\n",
              "      <td>2014</td>\n",
              "      <td>28729</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26998</td>\n",
              "      <td>2013</td>\n",
              "      <td>64032</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 616 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Price  Year  Mileage  M_1  M_15002WD  M_15004WD  M_1500Laramie  \\\n",
              "0  34995  2017     9913    0          0          0              0   \n",
              "1  37895  2015    20578    0          0          0              0   \n",
              "2  18430  2012    83716    0          0          0              0   \n",
              "3  24681  2014    28729    0          0          0              0   \n",
              "4  26998  2013    64032    0          0          0              0   \n",
              "\n",
              "   M_1500Tradesman  M_200LX  M_200Limited  ...  S__SD  S__TN  S__TX  S__UT  \\\n",
              "0                0        0             0  ...      0      0      0      0   \n",
              "1                0        0             0  ...      0      0      0      0   \n",
              "2                0        0             0  ...      0      0      1      0   \n",
              "3                0        0             0  ...      0      0      0      0   \n",
              "4                0        0             0  ...      0      0      0      0   \n",
              "\n",
              "   S__VA  S__VT  S__WA  S__WI  S__WV  S__WY  \n",
              "0      0      0      0      0      0      0  \n",
              "1      0      0      0      0      0      0  \n",
              "2      0      0      0      0      0      0  \n",
              "3      0      0      0      0      0      0  \n",
              "4      0      0      0      0      0      0  \n",
              "\n",
              "[5 rows x 616 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>M_200S</th>\n",
              "      <th>...</th>\n",
              "      <th>S__SD</th>\n",
              "      <th>S__TN</th>\n",
              "      <th>S__TX</th>\n",
              "      <th>S__UT</th>\n",
              "      <th>S__VA</th>\n",
              "      <th>S__VT</th>\n",
              "      <th>S__WA</th>\n",
              "      <th>S__WI</th>\n",
              "      <th>S__WV</th>\n",
              "      <th>S__WY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014</td>\n",
              "      <td>31909</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017</td>\n",
              "      <td>5362</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014</td>\n",
              "      <td>50300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004</td>\n",
              "      <td>132160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>25226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 615 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Year  Mileage  M_1  M_15002WD  M_15004WD  M_1500Laramie  M_1500Tradesman  \\\n",
              "ID                                                                             \n",
              "0   2014    31909    0          0          0              0                0   \n",
              "1   2017     5362    0          0          0              0                0   \n",
              "2   2014    50300    0          0          0              0                0   \n",
              "3   2004   132160    0          0          0              0                0   \n",
              "4   2015    25226    0          0          0              0                0   \n",
              "\n",
              "    M_200LX  M_200Limited  M_200S  ...  S__SD  S__TN  S__TX  S__UT  S__VA  \\\n",
              "ID                                 ...                                      \n",
              "0         0             0       0  ...      0      0      0      0      0   \n",
              "1         0             0       0  ...      0      0      0      0      0   \n",
              "2         0             0       0  ...      0      0      0      0      0   \n",
              "3         0             0       0  ...      0      0      0      0      0   \n",
              "4         0             0       0  ...      0      0      0      0      0   \n",
              "\n",
              "    S__VT  S__WA  S__WI  S__WV  S__WY  \n",
              "ID                                     \n",
              "0       0      0      0      0      0  \n",
              "1       0      0      0      0      0  \n",
              "2       0      0      0      0      0  \n",
              "3       0      1      0      0      0  \n",
              "4       0      0      0      0      0  \n",
              "\n",
              "[5 rows x 615 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#eliminacion de caracteres problematicos en el nombre de las columans\n",
        "\n",
        "import re\n",
        "\n",
        "# función para limpiar los nombres de las columnas\n",
        "def limpia_columna_nom(column_name):\n",
        "    # Reemplazar todos los caracteres no alfanuméricos con un guión bajo\n",
        "    return re.sub(r'\\W', '_', column_name)\n",
        "\n",
        "# aplicar la función a cada nombre de columna en dataTraining\n",
        "dataTraining.columns = [limpia_columna_nom(col) for col in dataTraining.columns]\n",
        "display(dataTraining.head())\n",
        "\n",
        "dataTraining.head()\n",
        "\n",
        "\n",
        "# aplicar la función a cada nombre de columna en dataTraining\n",
        "dataTesting.columns = [limpia_columna_nom(col) for col in dataTesting.columns]\n",
        "display(dataTesting.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e8f7be8",
      "metadata": {
        "id": "4e8f7be8"
      },
      "source": [
        "Division de de datos en conjunto de entrenamiento y prueba, asi como predictores y variables objetivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3669791c",
      "metadata": {
        "id": "3669791c"
      },
      "outputs": [],
      "source": [
        "# Separación de variables predictoras (X) y variable de interés (y)\n",
        "y = dataTraining['Price']\n",
        "X = dataTraining.drop(['Price'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4112f3e",
      "metadata": {
        "id": "a4112f3e",
        "outputId": "b7fcd709-30ad-4700-9217-1ac021a19d82"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>M_1</th>\n",
              "      <th>M_15002WD</th>\n",
              "      <th>M_15004WD</th>\n",
              "      <th>M_1500Laramie</th>\n",
              "      <th>M_1500Tradesman</th>\n",
              "      <th>M_200LX</th>\n",
              "      <th>M_200Limited</th>\n",
              "      <th>M_200S</th>\n",
              "      <th>...</th>\n",
              "      <th>S__SD</th>\n",
              "      <th>S__TN</th>\n",
              "      <th>S__TX</th>\n",
              "      <th>S__UT</th>\n",
              "      <th>S__VA</th>\n",
              "      <th>S__VT</th>\n",
              "      <th>S__WA</th>\n",
              "      <th>S__WI</th>\n",
              "      <th>S__WV</th>\n",
              "      <th>S__WY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>...</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "      <td>400000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2013.20</td>\n",
              "      <td>55072.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.29</td>\n",
              "      <td>40881.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1997.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2012.00</td>\n",
              "      <td>25841.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2014.00</td>\n",
              "      <td>42955.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2016.00</td>\n",
              "      <td>77433.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2018.00</td>\n",
              "      <td>2457832.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 615 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Year    Mileage       M_1  M_15002WD  M_15004WD  M_1500Laramie  \\\n",
              "count 400000.00  400000.00 400000.00  400000.00  400000.00      400000.00   \n",
              "mean    2013.20   55072.96      0.00       0.00       0.00           0.00   \n",
              "std        3.29   40881.02      0.02       0.03       0.05           0.03   \n",
              "min     1997.00       5.00      0.00       0.00       0.00           0.00   \n",
              "25%     2012.00   25841.00      0.00       0.00       0.00           0.00   \n",
              "50%     2014.00   42955.00      0.00       0.00       0.00           0.00   \n",
              "75%     2016.00   77433.00      0.00       0.00       0.00           0.00   \n",
              "max     2018.00 2457832.00      1.00       1.00       1.00           1.00   \n",
              "\n",
              "       M_1500Tradesman   M_200LX  M_200Limited    M_200S  ...     S__SD  \\\n",
              "count        400000.00 400000.00     400000.00 400000.00  ... 400000.00   \n",
              "mean              0.00      0.00          0.01      0.00  ...      0.00   \n",
              "std               0.02      0.02          0.07      0.04  ...      0.04   \n",
              "min               0.00      0.00          0.00      0.00  ...      0.00   \n",
              "25%               0.00      0.00          0.00      0.00  ...      0.00   \n",
              "50%               0.00      0.00          0.00      0.00  ...      0.00   \n",
              "75%               0.00      0.00          0.00      0.00  ...      0.00   \n",
              "max               1.00      1.00          1.00      1.00  ...      1.00   \n",
              "\n",
              "          S__TN     S__TX     S__UT     S__VA     S__VT     S__WA     S__WI  \\\n",
              "count 400000.00 400000.00 400000.00 400000.00 400000.00 400000.00 400000.00   \n",
              "mean       0.02      0.11      0.01      0.04      0.00      0.03      0.01   \n",
              "std        0.15      0.32      0.11      0.20      0.04      0.16      0.12   \n",
              "min        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
              "25%        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
              "50%        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
              "75%        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
              "max        1.00      1.00      1.00      1.00      1.00      1.00      1.00   \n",
              "\n",
              "          S__WV     S__WY  \n",
              "count 400000.00 400000.00  \n",
              "mean       0.00      0.00  \n",
              "std        0.04      0.03  \n",
              "min        0.00      0.00  \n",
              "25%        0.00      0.00  \n",
              "50%        0.00      0.00  \n",
              "75%        0.00      0.00  \n",
              "max        1.00      1.00  \n",
              "\n",
              "[8 rows x 615 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# descripcion del entrenamiento X\n",
        "import pandas as pd\n",
        "#formato de numero\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "X.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2019d59e",
      "metadata": {
        "id": "2019d59e"
      },
      "source": [
        "Existen 400 mil observaciones y 615 columnas\n",
        "\n",
        "Year: los autos en el conjunto de datos varían desde 1997 hasta 2018, el año promedio de fabricación es aproximadamente 2013, la distribución parece bastante normal, ya que la media y la mediana (50%) son cercanas, la desviación estándar es de alrededor de 3.29 años, lo que indica que la mayoría de los autos se encuentran dentro de un rango de 3 años desde la media.\n",
        "\n",
        "Mileage: la distancia promedio recorrida es de aproximadamente 55000 millas (kilometraje del vehiculo), pero hay una gran variabilidad, como lo indica la desviación estándar de aproximadamente 40881 millas, también hay un valor máximo muy alto de más de 2 millones de millas y podria catalogarse como dato atipico, se permitira que los modelos le den manejo a este tipo de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd11305b",
      "metadata": {
        "id": "cd11305b",
        "outputId": "654cfe65-22fb-423b-8973-ede67d6db8dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count   400000.00\n",
              "mean     21146.92\n",
              "std      10753.66\n",
              "min       5001.00\n",
              "25%      13499.00\n",
              "50%      18450.00\n",
              "75%      26999.00\n",
              "max      79999.00\n",
              "Name: Price, dtype: float64"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b462674",
      "metadata": {
        "id": "8b462674"
      },
      "source": [
        "El total de observaciones es 400 mil, el precio medio de los vehículos es de aproximadamente 21146,92\n",
        "\n",
        "la desviacion estadar es de 10753,66, lo que sugiere que hay una variabilidad considerable en los precios de los vehículos\n",
        "\n",
        "el precio mínimo es de 5001 y el maximo de 79999, la mitad de los vehículos tienen un precio de $18450 o menos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef46d28d",
      "metadata": {
        "id": "ef46d28d"
      },
      "outputs": [],
      "source": [
        "#division\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e28d3b0",
      "metadata": {
        "id": "9e28d3b0",
        "outputId": "3218274e-4e0a-422d-c9d3-50e20d121ee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(268000, 616)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(132000,)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(X_train.shape)\n",
        "display(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe60b2ab",
      "metadata": {
        "id": "fe60b2ab"
      },
      "source": [
        "los datos quedan dividos en 268000 para entrenamiento y 132000 para prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de73562",
      "metadata": {
        "id": "3de73562"
      },
      "source": [
        "Se iniciara una prueba con variables transformadas y otra con variables originales para ver el comportamiento de los datos y la prediccion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34ad76a",
      "metadata": {
        "id": "a34ad76a",
        "outputId": "7603a321-ace7-4bae-93b0-19fd7441fd3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de componentes seleccionados para conservar el 97% de la varianza: 558\n",
            "Forma de los datos de entrenamiento después de PCA: (268000, 558)\n",
            "Forma de los datos de prueba después de PCA: (132000, 558)\n"
          ]
        }
      ],
      "source": [
        "#PCA\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pca_pipeline = make_pipeline(StandardScaler(), PCA(n_components=0.97)) # Conservar el 97% de varianza\n",
        "\n",
        "# ajustar y transformar los datos de entrenamiento\n",
        "XTrain_pca = pca_pipeline.fit_transform(X_train)\n",
        "\n",
        "# transformar los datos de prueba\n",
        "XTest_pca = pca_pipeline.transform(X_test)\n",
        "\n",
        "# obtener el numero de componentes\n",
        "n_components = pca_pipeline.named_steps['pca'].n_components_\n",
        "\n",
        "print(f\"Número de componentes seleccionados para conservar el 97% de la varianza: {n_components}\")\n",
        "print(f\"Forma de los datos de entrenamiento después de PCA: {XTrain_pca.shape}\")\n",
        "print(f\"Forma de los datos de prueba después de PCA: {XTest_pca.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d17ae8",
      "metadata": {
        "id": "84d17ae8",
        "outputId": "b1bff9b4-eb5d-4bfd-818e-e3961fd9e1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 43504406.61292842\n",
            "Root Mean Squared Error (RMSE): 6595.787035140569\n"
          ]
        }
      ],
      "source": [
        "# linear regresion con datos tranformados  PCA\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Entrenar el modelo de regresión lineal\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(XTrain_pca, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "yPred = regressor.predict(XTest_pca)\n",
        "\n",
        "# Calcular el Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, yPred)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# Calcular el Root Mean Squared Error (RMSE)\n",
        "rmse = sqrt(mse)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2d8e59",
      "metadata": {
        "id": "ff2d8e59",
        "outputId": "5bd05892-4762-4fe7-f6a7-b4b088c161db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 19156359.139841553\n",
            "Root Mean Squared Error (RMSE): 4376.7978180219325\n"
          ]
        }
      ],
      "source": [
        "# linear regresion con datos originales solo binarizacion de variables categoricas\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Entrenar el modelo de regresión lineal\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "yPred = regressor.predict(X_test)\n",
        "\n",
        "# Calcular el Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, yPred)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# Calcular el Root Mean Squared Error (RMSE)\n",
        "rmse = sqrt(mse)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cad12a8",
      "metadata": {
        "id": "5cad12a8"
      },
      "source": [
        "hasta este punto los datos datos originales (solo binarizacion de variables categoricas) tienen un mejor comportamiento en la prediccion. se procede con Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9fe0349",
      "metadata": {
        "id": "b9fe0349",
        "outputId": "534f243a-f8e5-42d6-94cc-7dfb252a0971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE) with Random Forest: 2342.0370224661906\n",
            "Root Mean Squared Error (RMSE) with Random Forest: 3759.3648597765136\n",
            "R Cuadrado (R2) with Random Forest: 0.8771585197662753\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Random forest base con tranformacion y PCA\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "\n",
        "# crear el modelo Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "\n",
        "#  entrenamiento\n",
        "rf_regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "# hacer predicciones con los datos de prueba\n",
        "y_pred_rf = rf_regressor.predict(X_test_scaled)\n",
        "\n",
        "# calcular MSE, RMSE y MAE\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse_rfreg = sqrt(mse_rf)\n",
        "mae_rfreg  = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rfreg = r2_score(y_test, y_pred_rf)\n",
        "print(f'Mean Absolute Error (MAE) with Random Forest: {mae_rfreg}')\n",
        "print(f'Root Mean Squared Error (RMSE) with Random Forest: {rmse_rfreg}')\n",
        "print(f'R Cuadrado (R2) with Random Forest: {r2_rfreg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68eacce4",
      "metadata": {
        "id": "68eacce4",
        "outputId": "3868b217-724f-43ec-9d55-bca9cec80f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE) with Random Forest: 2342.1906925783583\n",
            "Root Mean Squared Error (RMSE) with Random Forest: 3758.7676390044476\n",
            "R Cuadrado (R2) with Random Forest: 0.877197546388624\n"
          ]
        }
      ],
      "source": [
        "#Random forest datos originales solo binarizacion\n",
        "\n",
        "\n",
        "rf_regressor = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "\n",
        "#  entrenamiento\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# hacer predicciones con los datos de prueba\n",
        "y_pred_rf = rf_regressor.predict(X_test)\n",
        "\n",
        "# calcular MSE, RMSE y MAE\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse_rfreg = sqrt(mse_rf)\n",
        "mae_rfreg  = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rfreg = r2_score(y_test, y_pred_rf)\n",
        "print(f'Mean Absolute Error (MAE) with Random Forest: {mae_rfreg}')\n",
        "print(f'Root Mean Squared Error (RMSE) with Random Forest: {rmse_rfreg}')\n",
        "print(f'R Cuadrado (R2) with Random Forest: {r2_rfreg}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be147a00",
      "metadata": {
        "id": "be147a00"
      },
      "source": [
        "para este caso, parece que las características que se eliminaron al aplicar PCA tenían información relevante para predecir el precio del vehiculo\n",
        "\n",
        "La reducción de dimensionalidad puede ser muy útil cuando se enfrentan problemas de alta dimensionalidad o el \"curse of dimensionality\", pero si los modelos pueden manejar eficientemente la dimensionalidad alta y extraer patrones útiles de todas las variables, como parece ser el caso, entonces es lógico preferir trabajar con todos los datos originales para mejorar el rendimiento del modelo en la competencia. Además, la capacidad de los modelos modernos de aprendizaje automático para manejar un gran número de características sin necesidad de reducción previa es cada vez más avanzada, lo que puede hacer que técnicas como PCA o PLS sean menos necesarias en algunos contextos. Dado lo anterior como es una competencia y el RMSE mas bajo sera el ganador a partir de este punto se trabajara con los datos oriniales sin transformar y se eligira el mejor modelo que sepa ajustarse a la situacion.\n",
        "\n",
        "Por otro lado, los modelos como los árboles de decisión, los bosques aleatorios y los métodos basados en gradient boosting no requieren necesariamente de un escalamiento de los datos, ya que su estructura de decisión basada en umbrales no se ve afectada por la magnitud de las características. En estos casos, escalar los datos no mejora el rendimiento y, en algunas situaciones, podría incluso introducir cierta pérdida de precisión en la representación numérica.\n",
        "\n",
        "Tambien,si el conjunto de datos incluye características numéricas que son codificaciones de categorías (por ejemplo, codificación one-hot), escalar estas características podría no tener sentido y podría afectar negativamente el rendimiento del modelo.\n",
        "\n",
        "Por lo expuesto anteriormente desde este punto se trabajara con datos originales (solo binarización categorica)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e8b97b",
      "metadata": {
        "id": "b0e8b97b"
      },
      "source": [
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c50c9b43",
      "metadata": {
        "id": "c50c9b43"
      },
      "source": [
        "Se procedera con calibracion por optuna del modelo XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9b2a6e",
      "metadata": {
        "id": "ad9b2a6e",
        "outputId": "34683a0c-690f-4900-d6b4-a4f8ff21d246"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 06:00:11,321] A new study created in memory with name: no-name-3e8ce8b6-1e23-47f6-9ea4-ce6b47069322\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:01:01,047] Trial 0 finished with value: 3993.3655664122266 and parameters: {'max_depth': 9, 'learning_rate': 0.09187617100131613, 'n_estimators': 274, 'subsample': 0.6614341326615689, 'colsample_bytree': 0.7496587272088036, 'min_child_weight': 4, 'gamma': 0.798699774385231}. Best is trial 0 with value: 3993.3655664122266.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:01:47,976] Trial 1 finished with value: 4857.735104245999 and parameters: {'max_depth': 3, 'learning_rate': 0.20164238176749313, 'n_estimators': 225, 'subsample': 0.9911656288361672, 'colsample_bytree': 0.6185019464398549, 'min_child_weight': 7, 'gamma': 0.11134028488905445}. Best is trial 0 with value: 3993.3655664122266.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:02:12,636] Trial 2 finished with value: 5893.61519658142 and parameters: {'max_depth': 6, 'learning_rate': 0.0715372200921561, 'n_estimators': 106, 'subsample': 0.7536115347259531, 'colsample_bytree': 0.9189059305012832, 'min_child_weight': 8, 'gamma': 0.21536017428564236}. Best is trial 0 with value: 3993.3655664122266.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:02:49,009] Trial 3 finished with value: 5153.662970808075 and parameters: {'max_depth': 4, 'learning_rate': 0.14252427808381765, 'n_estimators': 169, 'subsample': 0.9381911869184348, 'colsample_bytree': 0.6801692382413542, 'min_child_weight': 7, 'gamma': 0.43616959971335345}. Best is trial 0 with value: 3993.3655664122266.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:03:30,602] Trial 4 finished with value: 3798.9442651489953 and parameters: {'max_depth': 9, 'learning_rate': 0.18302397200148313, 'n_estimators': 192, 'subsample': 0.7316377811283323, 'colsample_bytree': 0.6907662316107208, 'min_child_weight': 8, 'gamma': 0.5526394291590877}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:04:25,331] Trial 5 finished with value: 4535.4416985820935 and parameters: {'max_depth': 5, 'learning_rate': 0.12070189342211145, 'n_estimators': 258, 'subsample': 0.8229839744513945, 'colsample_bytree': 0.9865783531612637, 'min_child_weight': 5, 'gamma': 0.8935531768878424}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:05:00,860] Trial 6 finished with value: 5198.825248329046 and parameters: {'max_depth': 4, 'learning_rate': 0.1400759363525909, 'n_estimators': 165, 'subsample': 0.8491556500633121, 'colsample_bytree': 0.7377355951401245, 'min_child_weight': 7, 'gamma': 0.6144448457467788}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:05:48,507] Trial 7 finished with value: 4817.295523496161 and parameters: {'max_depth': 6, 'learning_rate': 0.0846141654010048, 'n_estimators': 222, 'subsample': 0.652195102887523, 'colsample_bytree': 0.7567672346790268, 'min_child_weight': 9, 'gamma': 0.5379604964642575}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:06:08,794] Trial 8 finished with value: 4740.433957267362 and parameters: {'max_depth': 6, 'learning_rate': 0.23242873681791967, 'n_estimators': 86, 'subsample': 0.9681666821279119, 'colsample_bytree': 0.991565200796115, 'min_child_weight': 10, 'gamma': 0.38323413394584915}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:06:40,304] Trial 9 finished with value: 5783.014039489715 and parameters: {'max_depth': 4, 'learning_rate': 0.10204381594463416, 'n_estimators': 144, 'subsample': 0.6755365015594973, 'colsample_bytree': 0.7308079300422266, 'min_child_weight': 9, 'gamma': 0.55418197243866}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:06:53,634] Trial 10 finished with value: 4419.11195430664 and parameters: {'max_depth': 10, 'learning_rate': 0.285614089125223, 'n_estimators': 51, 'subsample': 0.5401456855935893, 'colsample_bytree': 0.5153040310986257, 'min_child_weight': 1, 'gamma': 0.7365238219724817}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:07:59,631] Trial 11 finished with value: 6028.058497830045 and parameters: {'max_depth': 9, 'learning_rate': 0.012565213593798169, 'n_estimators': 284, 'subsample': 0.603310479703072, 'colsample_bytree': 0.8372156253232159, 'min_child_weight': 4, 'gamma': 0.9861788323228624}. Best is trial 4 with value: 3798.9442651489953.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:09:01,374] Trial 12 finished with value: 3633.643342078252 and parameters: {'max_depth': 8, 'learning_rate': 0.19281050085199208, 'n_estimators': 294, 'subsample': 0.7272073590909232, 'colsample_bytree': 0.6085643275389367, 'min_child_weight': 3, 'gamma': 0.7648854979549184}. Best is trial 12 with value: 3633.643342078252.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:09:48,198] Trial 13 finished with value: 3739.8624884687647 and parameters: {'max_depth': 8, 'learning_rate': 0.21112691478100415, 'n_estimators': 220, 'subsample': 0.7521457271891494, 'colsample_bytree': 0.5785161450899866, 'min_child_weight': 2, 'gamma': 0.7061126794321531}. Best is trial 12 with value: 3633.643342078252.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:10:40,599] Trial 14 finished with value: 3627.903353992804 and parameters: {'max_depth': 8, 'learning_rate': 0.250914330152326, 'n_estimators': 244, 'subsample': 0.7782995044480536, 'colsample_bytree': 0.5326592749972091, 'min_child_weight': 1, 'gamma': 0.7119590640746496}. Best is trial 14 with value: 3627.903353992804.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:11:44,518] Trial 15 finished with value: 3562.6737280661505 and parameters: {'max_depth': 8, 'learning_rate': 0.26427028174808914, 'n_estimators': 299, 'subsample': 0.8436292436926129, 'colsample_bytree': 0.5099820200037641, 'min_child_weight': 2, 'gamma': 0.8541023064513963}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:12:36,954] Trial 16 finished with value: 3636.605442883923 and parameters: {'max_depth': 7, 'learning_rate': 0.2972272894564045, 'n_estimators': 250, 'subsample': 0.8634051688406384, 'colsample_bytree': 0.5120880031561101, 'min_child_weight': 2, 'gamma': 0.9972535593867798}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:13:38,178] Trial 17 finished with value: 3608.0296750726707 and parameters: {'max_depth': 7, 'learning_rate': 0.25230145041641616, 'n_estimators': 296, 'subsample': 0.9065849324006103, 'colsample_bytree': 0.5571929925780572, 'min_child_weight': 1, 'gamma': 0.8637848735850232}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:14:39,706] Trial 18 finished with value: 3607.6625334791197 and parameters: {'max_depth': 7, 'learning_rate': 0.2560077741197369, 'n_estimators': 297, 'subsample': 0.9082392758528016, 'colsample_bytree': 0.5691256549852913, 'min_child_weight': 3, 'gamma': 0.8844760958384524}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:15:24,833] Trial 19 finished with value: 3566.811313453488 and parameters: {'max_depth': 10, 'learning_rate': 0.26818548960188426, 'n_estimators': 204, 'subsample': 0.9015755974685342, 'colsample_bytree': 0.6308676612112968, 'min_child_weight': 3, 'gamma': 0.8964028682020929}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:16:07,280] Trial 20 finished with value: 3576.070212545158 and parameters: {'max_depth': 10, 'learning_rate': 0.270682092007083, 'n_estimators': 197, 'subsample': 0.8051879144217742, 'colsample_bytree': 0.6493077706136389, 'min_child_weight': 5, 'gamma': 0.34147001316417736}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:16:47,711] Trial 21 finished with value: 3581.622042119296 and parameters: {'max_depth': 10, 'learning_rate': 0.27250009979050177, 'n_estimators': 188, 'subsample': 0.8090779543898071, 'colsample_bytree': 0.631694735836942, 'min_child_weight': 5, 'gamma': 0.3176172220041314}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:17:18,619] Trial 22 finished with value: 3793.761461530248 and parameters: {'max_depth': 10, 'learning_rate': 0.22725910711738206, 'n_estimators': 135, 'subsample': 0.8798271049122157, 'colsample_bytree': 0.6701668987452667, 'min_child_weight': 3, 'gamma': 0.24302617717096653}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:18:02,196] Trial 23 finished with value: 3598.3221607184337 and parameters: {'max_depth': 9, 'learning_rate': 0.2738439046581393, 'n_estimators': 205, 'subsample': 0.8042313667772679, 'colsample_bytree': 0.8315289488629413, 'min_child_weight': 4, 'gamma': 0.0505099747007598}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:18:34,677] Trial 24 finished with value: 3922.695582705419 and parameters: {'max_depth': 10, 'learning_rate': 0.17175427223900638, 'n_estimators': 143, 'subsample': 0.9355595066773816, 'colsample_bytree': 0.6500464618364054, 'min_child_weight': 6, 'gamma': 0.45034829321410275}. Best is trial 15 with value: 3562.6737280661505.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:19:30,706] Trial 25 finished with value: 3521.967850650295 and parameters: {'max_depth': 9, 'learning_rate': 0.2987986998990279, 'n_estimators': 266, 'subsample': 0.839357408194147, 'colsample_bytree': 0.590819475820234, 'min_child_weight': 2, 'gamma': 0.6161991750025148}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 06:20:27,238] Trial 26 finished with value: 3548.8423328609865 and parameters: {'max_depth': 8, 'learning_rate': 0.2982546325620441, 'n_estimators': 268, 'subsample': 0.8586146502506258, 'colsample_bytree': 0.5826343393218673, 'min_child_weight': 2, 'gamma': 0.6427358731435061}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:21:23,596] Trial 27 finished with value: 3556.2185063987627 and parameters: {'max_depth': 8, 'learning_rate': 0.29353539490480124, 'n_estimators': 271, 'subsample': 0.8519961583444118, 'colsample_bytree': 0.5949354323132119, 'min_child_weight': 2, 'gamma': 0.6172898907985274}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:22:21,680] Trial 28 finished with value: 3549.45640532911 and parameters: {'max_depth': 8, 'learning_rate': 0.2993556597209957, 'n_estimators': 267, 'subsample': 0.6981215989360812, 'colsample_bytree': 0.5801833348436624, 'min_child_weight': 2, 'gamma': 0.6237707014107731}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:23:19,129] Trial 29 finished with value: 3568.718211444808 and parameters: {'max_depth': 9, 'learning_rate': 0.2290251587090144, 'n_estimators': 264, 'subsample': 0.7010874884730263, 'colsample_bytree': 0.5599318113579264, 'min_child_weight': 4, 'gamma': 0.6346403339927994}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:24:09,459] Trial 30 finished with value: 3601.8065183209105 and parameters: {'max_depth': 7, 'learning_rate': 0.2966069572771905, 'n_estimators': 241, 'subsample': 0.6281692086136892, 'colsample_bytree': 0.778757707178861, 'min_child_weight': 1, 'gamma': 0.6633410971329154}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:25:07,049] Trial 31 finished with value: 3538.9201690528917 and parameters: {'max_depth': 8, 'learning_rate': 0.299213910912144, 'n_estimators': 274, 'subsample': 0.7784012361006315, 'colsample_bytree': 0.5933227434546025, 'min_child_weight': 2, 'gamma': 0.5975136463011903}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:26:05,359] Trial 32 finished with value: 3549.9788769224424 and parameters: {'max_depth': 8, 'learning_rate': 0.29862728444769626, 'n_estimators': 279, 'subsample': 0.7732736556900098, 'colsample_bytree': 0.5444667515528776, 'min_child_weight': 2, 'gamma': 0.4805624801415901}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:26:54,804] Trial 33 finished with value: 3584.9052045267563 and parameters: {'max_depth': 9, 'learning_rate': 0.23952075337124845, 'n_estimators': 234, 'subsample': 0.6877621076568287, 'colsample_bytree': 0.5980414787954156, 'min_child_weight': 3, 'gamma': 0.5907952816926725}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:27:49,720] Trial 34 finished with value: 3601.9550942491196 and parameters: {'max_depth': 7, 'learning_rate': 0.28303709539071475, 'n_estimators': 265, 'subsample': 0.7812608125694103, 'colsample_bytree': 0.6979085862801179, 'min_child_weight': 2, 'gamma': 0.8004617191283698}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:28:47,391] Trial 35 finished with value: 3627.6768196691078 and parameters: {'max_depth': 8, 'learning_rate': 0.21657858382844092, 'n_estimators': 276, 'subsample': 0.7037336421982676, 'colsample_bytree': 0.605488538839472, 'min_child_weight': 1, 'gamma': 0.51468671352109}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:29:42,380] Trial 36 finished with value: 4709.852096117093 and parameters: {'max_depth': 9, 'learning_rate': 0.048961374947189454, 'n_estimators': 254, 'subsample': 0.7352556559138147, 'colsample_bytree': 0.5768727667935579, 'min_child_weight': 4, 'gamma': 0.6787780573697102}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:30:31,534] Trial 37 finished with value: 3868.830164079501 and parameters: {'max_depth': 5, 'learning_rate': 0.28187847548858214, 'n_estimators': 234, 'subsample': 0.5658117072691022, 'colsample_bytree': 0.6623245536870325, 'min_child_weight': 3, 'gamma': 0.8059138258762348}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:31:31,509] Trial 38 finished with value: 3542.7062667578393 and parameters: {'max_depth': 9, 'learning_rate': 0.24748434646516515, 'n_estimators': 281, 'subsample': 0.9937374800985999, 'colsample_bytree': 0.7166390828277087, 'min_child_weight': 2, 'gamma': 0.414205916836223}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:32:31,743] Trial 39 finished with value: 3548.6957638356444 and parameters: {'max_depth': 9, 'learning_rate': 0.23945493658248926, 'n_estimators': 285, 'subsample': 0.9861770172227169, 'colsample_bytree': 0.7121251061685189, 'min_child_weight': 1, 'gamma': 0.39439171341850177}. Best is trial 25 with value: 3521.967850650295.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:33:35,383] Trial 40 finished with value: 3626.0122059138153 and parameters: {'max_depth': 9, 'learning_rate': 0.18128049171781796, 'n_estimators': 288, 'subsample': 0.9956137170135724, 'colsample_bytree': 0.7093703508218898, 'min_child_weight': 1, 'gamma': 0.2002360324967013}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:34:35,030] Trial 41 finished with value: 3543.4621705120967 and parameters: {'max_depth': 9, 'learning_rate': 0.2436803372038087, 'n_estimators': 280, 'subsample': 0.9585331105235126, 'colsample_bytree': 0.8036769638780953, 'min_child_weight': 1, 'gamma': 0.39681248175210126}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:35:34,873] Trial 42 finished with value: 3539.9848141883804 and parameters: {'max_depth': 9, 'learning_rate': 0.24271728968847497, 'n_estimators': 282, 'subsample': 0.9517942407749532, 'colsample_bytree': 0.7973810026756145, 'min_child_weight': 1, 'gamma': 0.39578089815034434}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:36:29,538] Trial 43 finished with value: 3712.4956519045827 and parameters: {'max_depth': 9, 'learning_rate': 0.1613563565951284, 'n_estimators': 254, 'subsample': 0.951497494126905, 'colsample_bytree': 0.8023913149674952, 'min_child_weight': 1, 'gamma': 0.2851708439750402}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:37:26,727] Trial 44 finished with value: 4617.38993800051 and parameters: {'max_depth': 3, 'learning_rate': 0.20193282021748798, 'n_estimators': 278, 'subsample': 0.9628766403864693, 'colsample_bytree': 0.865188316898441, 'min_child_weight': 2, 'gamma': 0.4135187499426892}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:38:15,766] Trial 45 finished with value: 3585.7487456138338 and parameters: {'max_depth': 9, 'learning_rate': 0.2493673144919149, 'n_estimators': 230, 'subsample': 0.9275816017629002, 'colsample_bytree': 0.8991364166727513, 'min_child_weight': 6, 'gamma': 0.469425063368329}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:39:11,670] Trial 46 finished with value: 3738.3411576486537 and parameters: {'max_depth': 10, 'learning_rate': 0.128125996473598, 'n_estimators': 258, 'subsample': 0.9766096311357476, 'colsample_bytree': 0.7657997998290156, 'min_child_weight': 1, 'gamma': 0.3551339318697313}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:39:58,301] Trial 47 finished with value: 3661.6229053402144 and parameters: {'max_depth': 9, 'learning_rate': 0.21588582980035392, 'n_estimators': 216, 'subsample': 0.9514341463133692, 'colsample_bytree': 0.7853102830917831, 'min_child_weight': 3, 'gamma': 0.5427879043695598}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:40:50,586] Trial 48 finished with value: 3560.525832961767 and parameters: {'max_depth': 9, 'learning_rate': 0.260437636143557, 'n_estimators': 244, 'subsample': 0.891683079742686, 'colsample_bytree': 0.9469266268007328, 'min_child_weight': 2, 'gamma': 0.1610110796410159}. Best is trial 25 with value: 3521.967850650295.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:41:51,688] Trial 49 finished with value: 3509.0812278084873 and parameters: {'max_depth': 10, 'learning_rate': 0.24429529084241022, 'n_estimators': 285, 'subsample': 0.924802720144383, 'colsample_bytree': 0.8158990027271603, 'min_child_weight': 1, 'gamma': 0.4241372209084346}. Best is trial 49 with value: 3509.0812278084873.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:42:56,506] Trial 50 finished with value: 3477.791917384891 and parameters: {'max_depth': 10, 'learning_rate': 0.2818781034177894, 'n_estimators': 300, 'subsample': 0.8318224245397976, 'colsample_bytree': 0.7364197798413957, 'min_child_weight': 10, 'gamma': 0.5049174916625283}. Best is trial 50 with value: 3477.791917384891.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:44:00,565] Trial 51 finished with value: 3478.3011557039595 and parameters: {'max_depth': 10, 'learning_rate': 0.27923782495725086, 'n_estimators': 300, 'subsample': 0.8225255554530946, 'colsample_bytree': 0.7441066907788076, 'min_child_weight': 10, 'gamma': 0.5709490922365336}. Best is trial 50 with value: 3477.791917384891.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:45:01,998] Trial 52 finished with value: 3485.1020889470415 and parameters: {'max_depth': 10, 'learning_rate': 0.28083861304405106, 'n_estimators': 289, 'subsample': 0.824634947923378, 'colsample_bytree': 0.7370901998494062, 'min_child_weight': 10, 'gamma': 0.5758565138211869}. Best is trial 50 with value: 3477.791917384891.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 06:45:56,950] Trial 53 finished with value: 3481.350193725297 and parameters: {'max_depth': 10, 'learning_rate': 0.28369296760790164, 'n_estimators': 298, 'subsample': 0.8303857536526094, 'colsample_bytree': 0.7424532005257644, 'min_child_weight': 10, 'gamma': 0.5812544072345996}. Best is trial 50 with value: 3477.791917384891.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:46:53,276] Trial 54 finished with value: 3482.504786527054 and parameters: {'max_depth': 10, 'learning_rate': 0.28368344143054525, 'n_estimators': 300, 'subsample': 0.8396847944340754, 'colsample_bytree': 0.7438241259237726, 'min_child_weight': 10, 'gamma': 0.5679992198161579}. Best is trial 50 with value: 3477.791917384891.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:47:46,211] Trial 55 finished with value: 3474.952891200655 and parameters: {'max_depth': 10, 'learning_rate': 0.28241917159480556, 'n_estimators': 297, 'subsample': 0.829670936403927, 'colsample_bytree': 0.7441110394389674, 'min_child_weight': 10, 'gamma': 0.5106568602065065}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:48:40,396] Trial 56 finished with value: 3481.998032264636 and parameters: {'max_depth': 10, 'learning_rate': 0.28409718453147015, 'n_estimators': 299, 'subsample': 0.8290899677852059, 'colsample_bytree': 0.740506107661259, 'min_child_weight': 10, 'gamma': 0.5608442967817778}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:49:32,983] Trial 57 finished with value: 3488.0679528589 and parameters: {'max_depth': 10, 'learning_rate': 0.2669031007431482, 'n_estimators': 298, 'subsample': 0.8745453715411954, 'colsample_bytree': 0.7500581858399152, 'min_child_weight': 9, 'gamma': 0.5194017997692678}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:50:25,109] Trial 58 finished with value: 3475.1086284556523 and parameters: {'max_depth': 10, 'learning_rate': 0.2852264623818236, 'n_estimators': 297, 'subsample': 0.8259783763785311, 'colsample_bytree': 0.689347147564955, 'min_child_weight': 9, 'gamma': 0.5659089469317031}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:50:42,056] Trial 59 finished with value: 3983.5078004526436 and parameters: {'max_depth': 10, 'learning_rate': 0.25952518074900993, 'n_estimators': 87, 'subsample': 0.821767822392008, 'colsample_bytree': 0.6908456769166444, 'min_child_weight': 9, 'gamma': 0.4940620354656269}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:51:33,878] Trial 60 finished with value: 3488.9429885568184 and parameters: {'max_depth': 10, 'learning_rate': 0.27442107283502964, 'n_estimators': 291, 'subsample': 0.8000467659026391, 'colsample_bytree': 0.7281052033817536, 'min_child_weight': 8, 'gamma': 0.725810023268982}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:52:28,236] Trial 61 finished with value: 3476.564191730257 and parameters: {'max_depth': 10, 'learning_rate': 0.28572587683326545, 'n_estimators': 298, 'subsample': 0.8369785834484209, 'colsample_bytree': 0.7621368052321088, 'min_child_weight': 10, 'gamma': 0.563477453355741}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:53:23,496] Trial 62 finished with value: 3476.7715398832825 and parameters: {'max_depth': 10, 'learning_rate': 0.289041376034853, 'n_estimators': 299, 'subsample': 0.8216371848940057, 'colsample_bytree': 0.7324957158361636, 'min_child_weight': 10, 'gamma': 0.5417246176533672}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:54:14,895] Trial 63 finished with value: 3482.6738580263354 and parameters: {'max_depth': 10, 'learning_rate': 0.2889924461358902, 'n_estimators': 291, 'subsample': 0.8699788387464407, 'colsample_bytree': 0.7621029963382471, 'min_child_weight': 10, 'gamma': 0.510642045739719}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:55:07,749] Trial 64 finished with value: 3490.828532041183 and parameters: {'max_depth': 10, 'learning_rate': 0.2605825248313036, 'n_estimators': 291, 'subsample': 0.8149110921755529, 'colsample_bytree': 0.6790711633600419, 'min_child_weight': 9, 'gamma': 0.45313879298922827}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:55:37,270] Trial 65 finished with value: 3605.81361727471 and parameters: {'max_depth': 10, 'learning_rate': 0.27725273981658244, 'n_estimators': 163, 'subsample': 0.7911302093743345, 'colsample_bytree': 0.7726562070261914, 'min_child_weight': 10, 'gamma': 0.682661182551443}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:56:29,778] Trial 66 finished with value: 3489.975753901876 and parameters: {'max_depth': 10, 'learning_rate': 0.26759834734992854, 'n_estimators': 300, 'subsample': 0.7574867385711946, 'colsample_bytree': 0.7215675705937303, 'min_child_weight': 8, 'gamma': 0.5310896600098021}. Best is trial 55 with value: 3474.952891200655.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:57:21,153] Trial 67 finished with value: 3487.432205140036 and parameters: {'max_depth': 10, 'learning_rate': 0.28896651431553433, 'n_estimators': 293, 'subsample': 0.8868690781400366, 'colsample_bytree': 0.6958965131182436, 'min_child_weight': 9, 'gamma': 0.4813836881976771}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:58:09,368] Trial 68 finished with value: 3494.3552290651537 and parameters: {'max_depth': 10, 'learning_rate': 0.2730075474181, 'n_estimators': 272, 'subsample': 0.8524204714261067, 'colsample_bytree': 0.7563898345943539, 'min_child_weight': 10, 'gamma': 0.6497878137653691}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:58:59,582] Trial 69 finished with value: 3494.5167909801444 and parameters: {'max_depth': 10, 'learning_rate': 0.254982014650534, 'n_estimators': 286, 'subsample': 0.7612352074459559, 'colsample_bytree': 0.8474486528619273, 'min_child_weight': 10, 'gamma': 0.5833100604114412}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 06:59:45,580] Trial 70 finished with value: 3808.4293196149492 and parameters: {'max_depth': 5, 'learning_rate': 0.2892287617011882, 'n_estimators': 260, 'subsample': 0.832029923081391, 'colsample_bytree': 0.780666911407327, 'min_child_weight': 9, 'gamma': 0.7496338522629787}. Best is trial 55 with value: 3474.952891200655.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:00:41,357] Trial 71 finished with value: 3473.441240568581 and parameters: {'max_depth': 10, 'learning_rate': 0.2792366412884527, 'n_estimators': 299, 'subsample': 0.794342216925258, 'colsample_bytree': 0.7375872260517697, 'min_child_weight': 10, 'gamma': 0.5526584195823997}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:01:29,796] Trial 72 finished with value: 3499.5225745025864 and parameters: {'max_depth': 10, 'learning_rate': 0.2772283361355742, 'n_estimators': 273, 'subsample': 0.8067130166647121, 'colsample_bytree': 0.7042557443707921, 'min_child_weight': 10, 'gamma': 0.5423650560958768}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:01:53,886] Trial 73 finished with value: 3758.4358226666686 and parameters: {'max_depth': 10, 'learning_rate': 0.26745624310403104, 'n_estimators': 121, 'subsample': 0.7935661539962242, 'colsample_bytree': 0.728151695543091, 'min_child_weight': 10, 'gamma': 0.5986646137015558}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:02:46,140] Trial 74 finished with value: 3474.150068185999 and parameters: {'max_depth': 10, 'learning_rate': 0.2903117540697624, 'n_estimators': 293, 'subsample': 0.8640021576119273, 'colsample_bytree': 0.6838413838983624, 'min_child_weight': 8, 'gamma': 0.4498364025159881}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:03:37,946] Trial 75 finished with value: 3479.6776097698153 and parameters: {'max_depth': 10, 'learning_rate': 0.2907842283075321, 'n_estimators': 292, 'subsample': 0.7446745677040805, 'colsample_bytree': 0.6713254336601119, 'min_child_weight': 8, 'gamma': 0.44346546863085623}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:04:30,329] Trial 76 finished with value: 4281.960799887072 and parameters: {'max_depth': 10, 'learning_rate': 0.05564216926090662, 'n_estimators': 283, 'subsample': 0.8611632387921238, 'colsample_bytree': 0.6567487433248147, 'min_child_weight': 9, 'gamma': 0.5042294061364148}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:05:19,052] Trial 77 finished with value: 3518.1276862024024 and parameters: {'max_depth': 9, 'learning_rate': 0.2622750337868802, 'n_estimators': 277, 'subsample': 0.8424291511448072, 'colsample_bytree': 0.6863138210241141, 'min_child_weight': 9, 'gamma': 0.47545683310296577}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:05:31,386] Trial 78 finished with value: 4406.917479793362 and parameters: {'max_depth': 10, 'learning_rate': 0.23226618333375432, 'n_estimators': 58, 'subsample': 0.7669893288628781, 'colsample_bytree': 0.6260503691142405, 'min_child_weight': 9, 'gamma': 0.5501470418781147}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:06:18,973] Trial 79 finished with value: 7060.795053825616 and parameters: {'max_depth': 4, 'learning_rate': 0.018675284881967263, 'n_estimators': 271, 'subsample': 0.8146830956219311, 'colsample_bytree': 0.7187195095973128, 'min_child_weight': 8, 'gamma': 0.34813010611874246}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:07:09,377] Trial 80 finished with value: 3519.661060507884 and parameters: {'max_depth': 9, 'learning_rate': 0.25409039805590294, 'n_estimators': 292, 'subsample': 0.9079870803288809, 'colsample_bytree': 0.7880657675428062, 'min_child_weight': 7, 'gamma': 0.6236118892233867}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:08:03,774] Trial 81 finished with value: 3487.9840402390582 and parameters: {'max_depth': 10, 'learning_rate': 0.2929047822563243, 'n_estimators': 293, 'subsample': 0.7434897078845394, 'colsample_bytree': 0.6393339509179258, 'min_child_weight': 7, 'gamma': 0.4371675565164702}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:08:53,884] Trial 82 finished with value: 3479.5261397299687 and parameters: {'max_depth': 10, 'learning_rate': 0.29119566824911086, 'n_estimators': 287, 'subsample': 0.7869100055479685, 'colsample_bytree': 0.6738797738177121, 'min_child_weight': 8, 'gamma': 0.452890669241652}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:09:44,010] Trial 83 finished with value: 3486.936794295358 and parameters: {'max_depth': 10, 'learning_rate': 0.27536340644157065, 'n_estimators': 285, 'subsample': 0.7867636065854422, 'colsample_bytree': 0.6765206516527257, 'min_child_weight': 10, 'gamma': 0.5282536808042881}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:10:33,075] Trial 84 finished with value: 3481.392640446588 and parameters: {'max_depth': 10, 'learning_rate': 0.2929039383184625, 'n_estimators': 278, 'subsample': 0.8456868448876935, 'colsample_bytree': 0.705266608107018, 'min_child_weight': 10, 'gamma': 0.4660330529085378}. Best is trial 71 with value: 3473.441240568581.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:11:26,251] Trial 85 finished with value: 3471.803025679836 and parameters: {'max_depth': 10, 'learning_rate': 0.29997496916926697, 'n_estimators': 300, 'subsample': 0.8596704409559047, 'colsample_bytree': 0.7525763793610099, 'min_child_weight': 9, 'gamma': 0.3681460566855342}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:12:17,920] Trial 86 finished with value: 3501.9272827584596 and parameters: {'max_depth': 9, 'learning_rate': 0.27880981589398107, 'n_estimators': 299, 'subsample': 0.8708314219911926, 'colsample_bytree': 0.7564467460836939, 'min_child_weight': 9, 'gamma': 0.37242164734079986}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:12:49,664] Trial 87 finished with value: 3654.376850160011 and parameters: {'max_depth': 9, 'learning_rate': 0.26947058082568015, 'n_estimators': 177, 'subsample': 0.8592050632205068, 'colsample_bytree': 0.7707371635616845, 'min_child_weight': 9, 'gamma': 0.3234273602230674}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:13:37,285] Trial 88 finished with value: 3489.642014626959 and parameters: {'max_depth': 10, 'learning_rate': 0.29824514474617, 'n_estimators': 263, 'subsample': 0.8888919561400971, 'colsample_bytree': 0.8182498465619148, 'min_child_weight': 10, 'gamma': 0.6952705298522553}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:14:27,304] Trial 89 finished with value: 3630.83765160789 and parameters: {'max_depth': 6, 'learning_rate': 0.2850675751111262, 'n_estimators': 295, 'subsample': 0.7205974925826815, 'colsample_bytree': 0.7307948169770649, 'min_child_weight': 10, 'gamma': 0.2964819483839334}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:15:17,572] Trial 90 finished with value: 3487.134493585502 and parameters: {'max_depth': 10, 'learning_rate': 0.29996347075046, 'n_estimators': 280, 'subsample': 0.8189324702943378, 'colsample_bytree': 0.750961192275084, 'min_child_weight': 9, 'gamma': 0.6043179342338255}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:16:10,984] Trial 91 finished with value: 3475.039191607879 and parameters: {'max_depth': 10, 'learning_rate': 0.2894503238313905, 'n_estimators': 287, 'subsample': 0.8063991180492237, 'colsample_bytree': 0.7140693851345284, 'min_child_weight': 8, 'gamma': 0.510149846672859}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:17:02,250] Trial 92 finished with value: 3483.4207897340016 and parameters: {'max_depth': 10, 'learning_rate': 0.28068035423159526, 'n_estimators': 285, 'subsample': 0.8022039949673624, 'colsample_bytree': 0.719373330419878, 'min_child_weight': 7, 'gamma': 0.5020850121891751}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:17:57,392] Trial 93 finished with value: 3480.5309501653755 and parameters: {'max_depth': 10, 'learning_rate': 0.28727984743926516, 'n_estimators': 300, 'subsample': 0.8374451074011142, 'colsample_bytree': 0.7004082639819773, 'min_child_weight': 8, 'gamma': 0.4926794040784718}. Best is trial 85 with value: 3471.803025679836.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:18:51,423] Trial 94 finished with value: 3479.5000368306332 and parameters: {'max_depth': 10, 'learning_rate': 0.27097913407806584, 'n_estimators': 295, 'subsample': 0.8484354846380996, 'colsample_bytree': 0.7370779302047031, 'min_child_weight': 10, 'gamma': 0.5692465802688053}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:19:38,893] Trial 95 finished with value: 3490.889609585995 and parameters: {'max_depth': 10, 'learning_rate': 0.27792874727969263, 'n_estimators': 270, 'subsample': 0.7704812328025372, 'colsample_bytree': 0.7651257409885684, 'min_child_weight': 9, 'gamma': 0.6588942059366216}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:20:35,838] Trial 96 finished with value: 3498.7558640726575 and parameters: {'max_depth': 9, 'learning_rate': 0.29224209391295225, 'n_estimators': 288, 'subsample': 0.826539069307745, 'colsample_bytree': 0.7127447468288328, 'min_child_weight': 10, 'gamma': 0.5538559204158285}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:21:24,792] Trial 97 finished with value: 3496.515287290034 and parameters: {'max_depth': 10, 'learning_rate': 0.26376564135784236, 'n_estimators': 275, 'subsample': 0.8807970355599579, 'colsample_bytree': 0.7914185700368773, 'min_child_weight': 10, 'gamma': 0.011997230518385082}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:22:16,014] Trial 98 finished with value: 3498.953388625522 and parameters: {'max_depth': 9, 'learning_rate': 0.2851378551930607, 'n_estimators': 281, 'subsample': 0.7973927942148656, 'colsample_bytree': 0.6868491762688947, 'min_child_weight': 9, 'gamma': 0.3728530405185322}. Best is trial 85 with value: 3471.803025679836.\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-04-27 07:23:08,775] Trial 99 finished with value: 3835.342133790602 and parameters: {'max_depth': 10, 'learning_rate': 0.09413975431758892, 'n_estimators': 293, 'subsample': 0.5101089154227871, 'colsample_bytree': 0.7449776516825518, 'min_child_weight': 10, 'gamma': 0.5226128378588766}. Best is trial 85 with value: 3471.803025679836.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lo mejor: {'max_depth': 10, 'learning_rate': 0.29997496916926697, 'n_estimators': 300, 'subsample': 0.8596704409559047, 'colsample_bytree': 0.7525763793610099, 'min_child_weight': 9, 'gamma': 0.3681460566855342}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "def para(trial):\n",
        "    param = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0)\n",
        "    }\n",
        "\n",
        "    modelo = xgb.XGBRegressor(**param)\n",
        "    modelo.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n",
        "    preds = modelo.predict(X_test)\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    return rmse\n",
        "\n",
        "revision = optuna.create_study(direction='minimize')\n",
        "revision.optimize(para, n_trials=100)\n",
        "\n",
        "print('lo mejor:', revision.best_trial.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d92481",
      "metadata": {
        "id": "49d92481"
      },
      "source": [
        "Dado los resultados de optuna se procede a correr el modelo con esta calibración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b0cbfa2",
      "metadata": {
        "id": "2b0cbfa2",
        "outputId": "fde6dfab-97ad-48da-db3d-79cf78ad3a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 12053416.249119665\n",
            "R2 Score: 0.8952325820860102\n",
            "RMSE 3471.803025679836\n"
          ]
        }
      ],
      "source": [
        "#modelo XGboost con optuna\n",
        "\n",
        "import xgboost as xgb\n",
        "from math import sqrt\n",
        "\n",
        "# Configuración de los parámetros de XGBoost\n",
        "paramsxg1 = {\n",
        "    'objective': 'reg:squarederror',  # Objetivo de regresión con error cuadrado\n",
        "    'max_depth': 10,                   # Profundidad máxima de los árboles\n",
        "    'learning_rate': 0.29997496916926697,             # Tasa de aprendizaje\n",
        "    'n_estimators': 300,              # Número de árboles a construir\n",
        "    'subsample': 0.8596704409559047,                 # Submuestra de datos para el entrenamiento de cada árbol\n",
        "    'colsample_bytree': 0.7525763793610099,          # Submuestra de características para el entrenamiento de cada árbol\n",
        "    'min_child_weight': 9,\n",
        "    'gamma':0.3681460566855342\n",
        "}\n",
        "\n",
        "# Creación del modelo\n",
        "model = xgb.XGBRegressor(**paramsxg1)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicción en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluación del modelo\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse=sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"R2 Score:\", r2)\n",
        "print(\"RMSE\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f23002",
      "metadata": {
        "id": "b7f23002"
      },
      "source": [
        "Dado que XGboost es un modelo de rapida ejecucion,  procederemos a ajustar algunos hiperparamentros de forma artesanal y verificar si los podemos mejorar partiendo de la base que optuna genero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7456885",
      "metadata": {
        "id": "f7456885",
        "outputId": "ac39a1f0-35d8-4320-c90b-0262f1be7319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 11857273.024657985\n",
            "R2 Score: 0.8969374447360224\n",
            "RMSE 3443.439127479675\n"
          ]
        }
      ],
      "source": [
        "# entrenamiento y validacion\n",
        "\n",
        "import xgboost as xgb\n",
        "from math import sqrt\n",
        "\n",
        "# Configuración de los parámetros de XGBoost\n",
        "paramsxg1 = {\n",
        "    'objective': 'reg:squarederror',  # Objetivo de regresión con error cuadrado\n",
        "    'max_depth': 10,                   # Profundidad máxima de los árboles\n",
        "    'learning_rate': 0.2,             # Tasa de aprendizaje\n",
        "    'n_estimators': 700,              # Número de árboles a construir\n",
        "    'subsample': 0.999,                 # Submuestra de datos para el entrenamiento de cada árbol\n",
        "    'colsample_bytree': 0.999,          # Submuestra de características para el entrenamiento de cada árbol\n",
        "    'min_child_weight': 6,\n",
        "    'gamma':2\n",
        "}\n",
        "\n",
        "# Creación del modelo\n",
        "model = xgb.XGBRegressor(**paramsxg1)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicción en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluación del modelo\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse=sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"R2 Score:\", r2)\n",
        "print(\"RMSE\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd995962",
      "metadata": {
        "id": "bd995962"
      },
      "source": [
        "Despues de la calibracion por optuna y posteriormente la calibracion manual, este es el mejor resultado obtenido, a continuacion se explicara que implica cada parametro:\n",
        "\n",
        "objective: especifica la función de pérdida que se va a minimizar durante el entrenamiento. En este caso, 'reg:squarederror' indica que se trata de una tarea de regresión con el error cuadrático como la métrica de pérdida, lo anterior significa que el modelo intentará minimizar la diferencia cuadrada entre las predicciones y los valores reales.\n",
        "\n",
        "max_depth: este parámetro define la profundidad máxima de los árboles que se construirán, limitar la profundidad del árbol ayuda a prevenir el sobreajuste, arboles más profundos permiten al modelo aprender relaciones más complejas, pero también pueden capturar ruido en los datos.\n",
        "\n",
        "\n",
        "learning_rate: también conocido como tasa de aprendizaje o \"eta\", controla la contribución de cada arbol al modelo final, un valor bajo hace que el modelo sea más robusto a la estructura específica del árbol, reduciendo el riesgo de sobreajuste, pero requiere más árboles (n_estimators) para ser efectivo.\n",
        "\n",
        "n_estimators: es el número de arboles que se construirán en el modelo, más árboles pueden hacer que el modelo sea más potente, pero también más lento para entrenar y más susceptible al sobreajuste si la tasa de aprendizaje no está bien ajustada.\n",
        "\n",
        "subsample: es la fracción de muestras utilizadas para entrenar cada árbol, si es menor que 1.0, entonces XGBoost utilizará un muestreo aleatorio de los datos, lo que puede ayudar a hacer que el modelo sea más robusto al sobreajuste.\n",
        "\n",
        "colsample_bytree: este parámetro controla la fracción de características (columnas) que se utilizarán para cada árbol, un valor menor que 1.0 significa que cada árbol usará una fracción aleatoria de las características, esto es útil para aumentar la diversidad de los árboles y, por tanto, mejorar el rendimiento del modelo.\n",
        "\n",
        "min_child_weight: es un parámetro que controla el umbral mínimo de suma de pesos de instancias necesarias en un nodo hijo, este se usa para controlar el sobreajuste, valores más altos evitan que el modelo aprenda relaciones demasiado específicas, favoreciendo estructuras de árbol más simples.\n",
        "\n",
        "gamma:  es el parámetro de poda mínima de pérdida, gamma especifica la reducción mínima en la pérdida requerida para hacer una partición adicional en un nodo del árbol, un valor más alto hace que el algoritmo sea más conservador, resultando en árboles más simples y menos complejos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b33da58c",
      "metadata": {
        "id": "b33da58c"
      },
      "source": [
        "_______"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "904c19e6",
      "metadata": {
        "id": "904c19e6"
      },
      "source": [
        "seguimos en busqueda del mejor valor de RMSE en este caso aplicaremos el modelo LightGBM\n",
        "\n",
        "LightGBM, que significa Light Gradient Boosting Machine, es una implementación del algoritmo Gradient Boosting Machine (GBM). Desarrollado por Microsoft, LightGBM es un marco de trabajo para el aprendizaje automático que utiliza algoritmos basados en árboles de decisión. Está diseñado para ser eficiente y capaz de manejar grandes volúmenes de datos, ofreciendo varias ventajas como una mayor velocidad de entrenamiento, menor uso de memoria y una mejor precisión.\n",
        "\n",
        "Dado el contexto de los datos y la cantidad grande de observaciones, este modelo parece adaptarse a lo requerido en cuanto menor tiempo de ejecucion y mejorar la precision para la competencia.\n",
        "\n",
        "calibracion con optuna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d918e8f",
      "metadata": {
        "id": "7d918e8f",
        "outputId": "9fea5fed-4084-4f25-b490-ce27d95764c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:45:45,661] A new study created in memory with name: no-name-7efedfc2-8e90-47c9-990e-3e2e764784c9\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:46:01,841] Trial 0 finished with value: 4199.455059838217 and parameters: {'boosting_type': 'dart', 'max_depth': 9, 'min_child_weight': 0.0413552029315324, 'num_leaves': 270, 'n_estimators': 254, 'reg_alpha': 0.21710530723677557, 'learning_rate': 0.23965619343716635, 'feature_fraction': 0.7935447552930517, 'bagging_fraction': 0.7249889525352836, 'bagging_freq': 7}. Best is trial 0 with value: 4199.455059838217.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:46:16,063] Trial 1 finished with value: 4226.983935162991 and parameters: {'boosting_type': 'dart', 'max_depth': 8, 'min_child_weight': 0.005989613940185355, 'num_leaves': 126, 'n_estimators': 257, 'reg_alpha': 0.5271088039992825, 'learning_rate': 0.2569628346488938, 'feature_fraction': 0.9323587792255943, 'bagging_fraction': 0.45974486210233156, 'bagging_freq': 4}. Best is trial 0 with value: 4199.455059838217.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:46:19,961] Trial 2 finished with value: 6265.183171009999 and parameters: {'boosting_type': 'dart', 'max_depth': 10, 'min_child_weight': 0.392105755291145, 'num_leaves': 281, 'n_estimators': 64, 'reg_alpha': 0.03974140725710806, 'learning_rate': 0.1479645556840744, 'feature_fraction': 0.9373946709740693, 'bagging_fraction': 0.5823728343768706, 'bagging_freq': 4}. Best is trial 0 with value: 4199.455059838217.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:46:23,016] Trial 3 finished with value: 4319.238959028738 and parameters: {'boosting_type': 'goss', 'max_depth': 5, 'min_child_weight': 0.004471533105867382, 'num_leaves': 146, 'n_estimators': 126, 'reg_alpha': 0.0598234563416804, 'learning_rate': 0.2881340679795803}. Best is trial 0 with value: 4199.455059838217.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:46:27,585] Trial 4 finished with value: 6445.491758158705 and parameters: {'boosting_type': 'dart', 'max_depth': 3, 'min_child_weight': 1.5874461658231342, 'num_leaves': 206, 'n_estimators': 168, 'reg_alpha': 0.20639931347655394, 'learning_rate': 0.2243967906452696, 'feature_fraction': 0.5356886273009241, 'bagging_fraction': 0.9678977496488687, 'bagging_freq': 1}. Best is trial 0 with value: 4199.455059838217.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:46:30,944] Trial 5 finished with value: 3764.5058402202944 and parameters: {'boosting_type': 'gbdt', 'max_depth': 10, 'min_child_weight': 0.027758380234590898, 'num_leaves': 257, 'n_estimators': 117, 'reg_alpha': 0.2656461869639223, 'learning_rate': 0.2908787590439783, 'feature_fraction': 0.8796363253214716, 'bagging_fraction': 0.5658637381252056, 'bagging_freq': 7}. Best is trial 5 with value: 3764.5058402202944.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:46:40,231] Trial 6 finished with value: 4898.114677927402 and parameters: {'boosting_type': 'dart', 'max_depth': 7, 'min_child_weight': 0.0074201406098892714, 'num_leaves': 48, 'n_estimators': 202, 'reg_alpha': 0.17001983318372682, 'learning_rate': 0.23180712445086168, 'feature_fraction': 0.5763391742443646, 'bagging_fraction': 0.4897443497843525, 'bagging_freq': 4}. Best is trial 5 with value: 3764.5058402202944.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:46:43,390] Trial 7 finished with value: 7182.535527662287 and parameters: {'boosting_type': 'gbdt', 'max_depth': 10, 'min_child_weight': 0.004969150681339956, 'num_leaves': 133, 'n_estimators': 65, 'reg_alpha': 0.5466609603554812, 'learning_rate': 0.020881315652008153, 'feature_fraction': 0.82526518554997, 'bagging_fraction': 0.5520343417060093, 'bagging_freq': 6}. Best is trial 5 with value: 3764.5058402202944.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:46:46,583] Trial 8 finished with value: 4161.35575965945 and parameters: {'boosting_type': 'goss', 'max_depth': 7, 'min_child_weight': 2.6897412945451595, 'num_leaves': 42, 'n_estimators': 131, 'reg_alpha': 0.44523987020613875, 'learning_rate': 0.22256353873268064}. Best is trial 5 with value: 3764.5058402202944.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:46:49,446] Trial 9 finished with value: 5505.945385146125 and parameters: {'boosting_type': 'gbdt', 'max_depth': 4, 'min_child_weight': 0.31324020409007636, 'num_leaves': 39, 'n_estimators': 152, 'reg_alpha': 0.7649202678746055, 'learning_rate': 0.11958373026457687, 'feature_fraction': 0.6595935914684787, 'bagging_fraction': 0.7536250551293449, 'bagging_freq': 1}. Best is trial 5 with value: 3764.5058402202944.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:46:52,476] Trial 10 finished with value: 5891.92810262492 and parameters: {'boosting_type': 'gbdt', 'max_depth': 6, 'min_child_weight': 0.047012821840543936, 'num_leaves': 219, 'n_estimators': 104, 'reg_alpha': 0.9260294644505703, 'learning_rate': 0.07438360752266923, 'feature_fraction': 0.45057250434088403, 'bagging_fraction': 0.8724580883618168, 'bagging_freq': 6}. Best is trial 5 with value: 3764.5058402202944.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:46:56,252] Trial 11 finished with value: 3714.9172408787767 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 8.74703180134626, 'num_leaves': 213, 'n_estimators': 203, 'reg_alpha': 0.3706734359461196, 'learning_rate': 0.2992542268006936}. Best is trial 11 with value: 3714.9172408787767.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:00,161] Trial 12 finished with value: 3672.333531913364 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 5.966512127315298, 'num_leaves': 213, 'n_estimators': 207, 'reg_alpha': 0.34332960735020773, 'learning_rate': 0.29333889639922417}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:04,042] Trial 13 finished with value: 3863.999718006653 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 9.678138486094383, 'num_leaves': 200, 'n_estimators': 212, 'reg_alpha': 0.3920553664545816, 'learning_rate': 0.1846909889806514}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:07,908] Trial 14 finished with value: 3703.975094889652 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 7.6221227041718835, 'num_leaves': 188, 'n_estimators': 216, 'reg_alpha': 0.6896844954297823, 'learning_rate': 0.29687934901099755}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:12,277] Trial 15 finished with value: 3735.249647442466 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 1.5931883670677236, 'num_leaves': 96, 'n_estimators': 280, 'reg_alpha': 0.652954040760791, 'learning_rate': 0.17787724333959393}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:15,876] Trial 16 finished with value: 3856.521455256743 and parameters: {'boosting_type': 'goss', 'max_depth': 6, 'min_child_weight': 0.36143536885938, 'num_leaves': 177, 'n_estimators': 228, 'reg_alpha': 0.7853893323450553, 'learning_rate': 0.26633599610576775}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:20,415] Trial 17 finished with value: 3673.8461178830644 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 3.087493059884249, 'num_leaves': 243, 'n_estimators': 299, 'reg_alpha': 0.6395683719027706, 'learning_rate': 0.200183994160732}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:24,883] Trial 18 finished with value: 3681.511754307569 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 3.6141962523699833, 'num_leaves': 242, 'n_estimators': 287, 'reg_alpha': 0.9567710050117237, 'learning_rate': 0.19191637005835646}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:29,317] Trial 19 finished with value: 3969.1086234912846 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 0.9484557273339727, 'num_leaves': 296, 'n_estimators': 257, 'reg_alpha': 0.5827893005005712, 'learning_rate': 0.10805666410864112}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:33,482] Trial 20 finished with value: 3882.9325635100813 and parameters: {'boosting_type': 'goss', 'max_depth': 7, 'min_child_weight': 0.14359729050606218, 'num_leaves': 251, 'n_estimators': 299, 'reg_alpha': 0.3279025031216792, 'learning_rate': 0.15284502398848201}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:47:38,099] Trial 21 finished with value: 3673.7067915945904 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 3.4853177500772037, 'num_leaves': 232, 'n_estimators': 295, 'reg_alpha': 0.9913166101803209, 'learning_rate': 0.19690183132535533}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:42,448] Trial 22 finished with value: 3681.953255686085 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 3.8990044186361863, 'num_leaves': 233, 'n_estimators': 245, 'reg_alpha': 0.8556306799316986, 'learning_rate': 0.20342483721110122}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:46,983] Trial 23 finished with value: 3848.664195245259 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 0.001301765629831249, 'num_leaves': 181, 'n_estimators': 269, 'reg_alpha': 0.9892026999561283, 'learning_rate': 0.12660138676647137}. Best is trial 12 with value: 3672.333531913364.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:51,326] Trial 24 finished with value: 3669.0894028795456 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 0.6620694817942686, 'num_leaves': 233, 'n_estimators': 293, 'reg_alpha': 0.4568600496448294, 'learning_rate': 0.259455058951523}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:54,927] Trial 25 finished with value: 3807.649611208816 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 0.7909034762690649, 'num_leaves': 168, 'n_estimators': 180, 'reg_alpha': 0.4511595308702101, 'learning_rate': 0.25713388457461894}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:47:58,702] Trial 26 finished with value: 3759.6811390195526 and parameters: {'boosting_type': 'goss', 'max_depth': 7, 'min_child_weight': 0.6319878052195779, 'num_leaves': 230, 'n_estimators': 233, 'reg_alpha': 0.47134107417579024, 'learning_rate': 0.2705384147476195}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:02,980] Trial 27 finished with value: 3684.879360761297 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 0.1336895047798572, 'num_leaves': 299, 'n_estimators': 272, 'reg_alpha': 0.31105155336886603, 'learning_rate': 0.24952176016059913}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:06,294] Trial 28 finished with value: 4293.553893254439 and parameters: {'boosting_type': 'gbdt', 'max_depth': 6, 'min_child_weight': 1.765612052307358, 'num_leaves': 268, 'n_estimators': 187, 'reg_alpha': 0.5934303301093086, 'learning_rate': 0.17114720447990192, 'feature_fraction': 0.4158296808116256, 'bagging_fraction': 0.824546000506161, 'bagging_freq': 2}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:10,650] Trial 29 finished with value: 3673.4035672176165 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 4.866280333744923, 'num_leaves': 268, 'n_estimators': 240, 'reg_alpha': 0.1256787426142425, 'learning_rate': 0.21408974766880992}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:48:27,618] Trial 30 finished with value: 3966.2941973672555 and parameters: {'boosting_type': 'dart', 'max_depth': 10, 'min_child_weight': 5.42077493495323, 'num_leaves': 283, 'n_estimators': 243, 'reg_alpha': 0.14217915349598634, 'learning_rate': 0.2769562166463232, 'feature_fraction': 0.7176964491391649, 'bagging_fraction': 0.998464428709863, 'bagging_freq': 3}. Best is trial 24 with value: 3669.0894028795456.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:31,980] Trial 31 finished with value: 3654.6100760420927 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 5.0869882571260305, 'num_leaves': 260, 'n_estimators': 266, 'reg_alpha': 0.09340024513832057, 'learning_rate': 0.24007432940870013}. Best is trial 31 with value: 3654.6100760420927.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:36,305] Trial 32 finished with value: 3676.10615802707 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 1.4802601998280551, 'num_leaves': 262, 'n_estimators': 259, 'reg_alpha': 0.12639846783586445, 'learning_rate': 0.24289922613144668}. Best is trial 31 with value: 3654.6100760420927.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:40,492] Trial 33 finished with value: 3681.791100013206 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 5.615860267057358, 'num_leaves': 270, 'n_estimators': 229, 'reg_alpha': 0.02037897443044351, 'learning_rate': 0.21621670417229516}. Best is trial 31 with value: 3654.6100760420927.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:48:45,111] Trial 34 finished with value: 3627.6569493824786 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.22738581445780992, 'num_leaves': 279, 'n_estimators': 268, 'reg_alpha': 0.06452775604587513, 'learning_rate': 0.2437856649845825}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:49:01,847] Trial 35 finished with value: 4106.0043011918515 and parameters: {'boosting_type': 'dart', 'max_depth': 9, 'min_child_weight': 0.1979118233375849, 'num_leaves': 279, 'n_estimators': 265, 'reg_alpha': 0.07161913355709325, 'learning_rate': 0.24422496507330765, 'feature_fraction': 0.9842262497687022, 'bagging_fraction': 0.6505552222371587, 'bagging_freq': 5}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:06,110] Trial 36 finished with value: 3666.6802546332524 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 0.05791086926661414, 'num_leaves': 197, 'n_estimators': 282, 'reg_alpha': 0.23723152328322583, 'learning_rate': 0.2768104279572147}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:49:22,331] Trial 37 finished with value: 4092.6947319236083 and parameters: {'boosting_type': 'dart', 'max_depth': 8, 'min_child_weight': 0.02682628467408959, 'num_leaves': 154, 'n_estimators': 278, 'reg_alpha': 0.23602800261431692, 'learning_rate': 0.2775212257022671, 'feature_fraction': 0.6963955257587484, 'bagging_fraction': 0.8898607856584783, 'bagging_freq': 2}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:26,046] Trial 38 finished with value: 3885.0602454646923 and parameters: {'boosting_type': 'goss', 'max_depth': 5, 'min_child_weight': 0.06218901414279614, 'num_leaves': 197, 'n_estimators': 285, 'reg_alpha': 0.07608547118186995, 'learning_rate': 0.2575859042877511}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:29,884] Trial 39 finished with value: 3706.084630941862 and parameters: {'boosting_type': 'gbdt', 'max_depth': 7, 'min_child_weight': 0.012324102154486651, 'num_leaves': 251, 'n_estimators': 259, 'reg_alpha': 0.0056277812284447615, 'learning_rate': 0.23517509026542552, 'feature_fraction': 0.5450886159222055, 'bagging_fraction': 0.6744990773526531, 'bagging_freq': 5}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:34,002] Trial 40 finished with value: 3686.2577621429305 and parameters: {'boosting_type': 'goss', 'max_depth': 8, 'min_child_weight': 0.09128578854628325, 'num_leaves': 283, 'n_estimators': 248, 'reg_alpha': 0.19646055552454456, 'learning_rate': 0.27699414612854284}. Best is trial 34 with value: 3627.6569493824786.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:38,564] Trial 41 finished with value: 3615.7386462502986 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.5564864646816645, 'num_leaves': 220, 'n_estimators': 275, 'reg_alpha': 0.2655327958194629, 'learning_rate': 0.2626369416784767}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:43,287] Trial 42 finished with value: 3628.636504660272 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.25347334623681333, 'num_leaves': 223, 'n_estimators': 283, 'reg_alpha': 0.2692752700718017, 'learning_rate': 0.22919837147671354}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:47,889] Trial 43 finished with value: 3644.3858738070594 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.24903309348701042, 'num_leaves': 222, 'n_estimators': 274, 'reg_alpha': 0.25533136595818445, 'learning_rate': 0.22957550410493163}. Best is trial 41 with value: 3615.7386462502986.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:49:52,372] Trial 44 finished with value: 3652.2917177098707 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.24452964515796644, 'num_leaves': 103, 'n_estimators': 272, 'reg_alpha': 0.27985055628837463, 'learning_rate': 0.21533319537836648}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:50:09,497] Trial 45 finished with value: 4153.400831354436 and parameters: {'boosting_type': 'dart', 'max_depth': 10, 'min_child_weight': 0.20283613117294091, 'num_leaves': 106, 'n_estimators': 254, 'reg_alpha': 0.28032474242679656, 'learning_rate': 0.23065459962351578, 'feature_fraction': 0.7803412887149492, 'bagging_fraction': 0.40934411227549294, 'bagging_freq': 3}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:13,134] Trial 46 finished with value: 3904.9276507830295 and parameters: {'boosting_type': 'gbdt', 'max_depth': 10, 'min_child_weight': 0.2744530394159099, 'num_leaves': 68, 'n_estimators': 157, 'reg_alpha': 0.2816193364275835, 'learning_rate': 0.16791709983040837, 'feature_fraction': 0.5983526508186359, 'bagging_fraction': 0.79479682980982, 'bagging_freq': 2}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:16,212] Trial 47 finished with value: 4364.172056883591 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.46032795528879344, 'num_leaves': 22, 'n_estimators': 88, 'reg_alpha': 0.3775013789896754, 'learning_rate': 0.21132886008931004}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:20,864] Trial 48 finished with value: 3632.8848243467846 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.2556776659480756, 'num_leaves': 137, 'n_estimators': 275, 'reg_alpha': 0.18056460309707045, 'learning_rate': 0.22265876924945888}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:24,967] Trial 49 finished with value: 3684.2231139833407 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.4384300402570201, 'num_leaves': 130, 'n_estimators': 221, 'reg_alpha': 0.17210379495633088, 'learning_rate': 0.22281399414526615}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:28,609] Trial 50 finished with value: 6364.848873171732 and parameters: {'boosting_type': 'goss', 'max_depth': 4, 'min_child_weight': 0.13077034422714187, 'num_leaves': 155, 'n_estimators': 287, 'reg_alpha': 0.21025992313583747, 'learning_rate': 0.03053754407449988}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:33,115] Trial 51 finished with value: 3630.494912095822 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.22230040417476166, 'num_leaves': 114, 'n_estimators': 272, 'reg_alpha': 0.1667976122245554, 'learning_rate': 0.2248035075754977}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:37,670] Trial 52 finished with value: 3633.701411513745 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.09262615099313035, 'num_leaves': 123, 'n_estimators': 273, 'reg_alpha': 0.16264389362756526, 'learning_rate': 0.2306044294982859}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:42,061] Trial 53 finished with value: 3644.286322331347 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.0847586080471653, 'num_leaves': 120, 'n_estimators': 255, 'reg_alpha': 0.17637233476496403, 'learning_rate': 0.2515317455051804}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:46,750] Trial 54 finished with value: 3639.8467724923034 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 0.031025154091720634, 'num_leaves': 140, 'n_estimators': 289, 'reg_alpha': 0.14024782327857746, 'learning_rate': 0.2068430556680571}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:50:51,304] Trial 55 finished with value: 3696.467991861957 and parameters: {'boosting_type': 'goss', 'max_depth': 9, 'min_child_weight': 0.167574514491422, 'num_leaves': 80, 'n_estimators': 279, 'reg_alpha': 0.04045439053357658, 'learning_rate': 0.18629959595815582}. Best is trial 41 with value: 3615.7386462502986.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:50:56,040] Trial 56 finished with value: 3596.2718159193505 and parameters: {'boosting_type': 'goss', 'max_depth': 10, 'min_child_weight': 1.015282668641339, 'num_leaves': 111, 'n_estimators': 300, 'reg_alpha': 0.10550465735762157, 'learning_rate': 0.28702710800794284}. Best is trial 56 with value: 3596.2718159193505.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:00,530] Trial 57 finished with value: 3530.1722184943833 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.066683280749443, 'num_leaves': 88, 'n_estimators': 292, 'reg_alpha': 0.10824457065601756, 'learning_rate': 0.26328790061170493, 'feature_fraction': 0.4860620885453086, 'bagging_fraction': 0.9234746285040697, 'bagging_freq': 6}. Best is trial 57 with value: 3530.1722184943833.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:04,982] Trial 58 finished with value: 3518.8457976253235 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.1455492132786267, 'num_leaves': 78, 'n_estimators': 290, 'reg_alpha': 0.0971412632583858, 'learning_rate': 0.29679310600933606, 'feature_fraction': 0.4793836102813844, 'bagging_fraction': 0.9219466604782717, 'bagging_freq': 6}. Best is trial 58 with value: 3518.8457976253235.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:09,553] Trial 59 finished with value: 3515.0730730820324 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.184214611914569, 'num_leaves': 85, 'n_estimators': 298, 'reg_alpha': 0.10738482698084051, 'learning_rate': 0.29032927599465497, 'feature_fraction': 0.4806775759655193, 'bagging_fraction': 0.9046966674320394, 'bagging_freq': 6}. Best is trial 59 with value: 3515.0730730820324.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:14,149] Trial 60 finished with value: 3511.6738580527826 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.1431893137969014, 'num_leaves': 82, 'n_estimators': 299, 'reg_alpha': 0.0989510274808229, 'learning_rate': 0.28657822394928195, 'feature_fraction': 0.4802099728688999, 'bagging_fraction': 0.9194624540707252, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:18,718] Trial 61 finished with value: 3512.612957274998 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.0639680444090547, 'num_leaves': 84, 'n_estimators': 299, 'reg_alpha': 0.1033228510447428, 'learning_rate': 0.28821655410276886, 'feature_fraction': 0.47124035561274524, 'bagging_fraction': 0.9353293119240401, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:23,301] Trial 62 finished with value: 3530.3560791859445 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.0927683823851673, 'num_leaves': 85, 'n_estimators': 296, 'reg_alpha': 0.10178800080895328, 'learning_rate': 0.28663808714521266, 'feature_fraction': 0.4784348339355037, 'bagging_fraction': 0.918124239856627, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:27,846] Trial 63 finished with value: 3526.437720634274 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.1786830942079463, 'num_leaves': 81, 'n_estimators': 300, 'reg_alpha': 0.10430356827399259, 'learning_rate': 0.2871340250997613, 'feature_fraction': 0.4803465355733767, 'bagging_fraction': 0.9200813573852833, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:32,395] Trial 64 finished with value: 3513.439964258343 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.452080964458655, 'num_leaves': 78, 'n_estimators': 294, 'reg_alpha': 0.026771021714332252, 'learning_rate': 0.2919075964400644, 'feature_fraction': 0.481946279163915, 'bagging_fraction': 0.9286908294327388, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:37,012] Trial 65 finished with value: 3521.0472213768844 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.1722109815183925, 'num_leaves': 54, 'n_estimators': 300, 'reg_alpha': 0.034399199243827255, 'learning_rate': 0.2993222343024802, 'feature_fraction': 0.49675047518198495, 'bagging_fraction': 0.934358704629562, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:51:41,593] Trial 66 finished with value: 3517.623550271715 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.136166163195258, 'num_leaves': 58, 'n_estimators': 300, 'reg_alpha': 0.03669677241320181, 'learning_rate': 0.29999614747765707, 'feature_fraction': 0.5026542763427315, 'bagging_fraction': 0.9491866890501888, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:45,876] Trial 67 finished with value: 3550.1040575179536 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 2.661067524890406, 'num_leaves': 54, 'n_estimators': 290, 'reg_alpha': 0.04007534311253863, 'learning_rate': 0.29992389863492686, 'feature_fraction': 0.514778933669065, 'bagging_fraction': 0.9603822246189039, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:50,270] Trial 68 finished with value: 3547.3338805775347 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.1035374015484427, 'num_leaves': 64, 'n_estimators': 292, 'reg_alpha': 0.006092526713247573, 'learning_rate': 0.29210040061878445, 'feature_fraction': 0.4096646880061374, 'bagging_fraction': 0.8503013448266349, 'bagging_freq': 7}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:54,690] Trial 69 finished with value: 3539.8188348623867 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.9082232958867589, 'num_leaves': 68, 'n_estimators': 284, 'reg_alpha': 0.038399095879855336, 'learning_rate': 0.2992995182062017, 'feature_fraction': 0.44776361627564537, 'bagging_fraction': 0.9486984910768332, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:51:57,508] Trial 70 finished with value: 4653.741199690327 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 2.4932221259467258, 'num_leaves': 27, 'n_estimators': 57, 'reg_alpha': 0.0494284076247538, 'learning_rate': 0.2702082787718553, 'feature_fraction': 0.5111120033462395, 'bagging_fraction': 0.8886030317979023, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:02,130] Trial 71 finished with value: 3527.6755625499563 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.2655832759602617, 'num_leaves': 54, 'n_estimators': 297, 'reg_alpha': 0.08449372464230115, 'learning_rate': 0.28309720400429583, 'feature_fraction': 0.46353139438121244, 'bagging_fraction': 0.9299691698315459, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:06,739] Trial 72 finished with value: 3523.3672248663775 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 0.7679142271539642, 'num_leaves': 77, 'n_estimators': 300, 'reg_alpha': 0.13429696810048697, 'learning_rate': 0.29091225349335126, 'feature_fraction': 0.4906184095634107, 'bagging_fraction': 0.9972163206552037, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:11,154] Trial 73 finished with value: 3532.980591228716 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 0.7936354520515455, 'num_leaves': 39, 'n_estimators': 289, 'reg_alpha': 0.0023269240605382283, 'learning_rate': 0.29283989147446776, 'feature_fraction': 0.5087114612469926, 'bagging_fraction': 0.9996629590533506, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:15,714] Trial 74 finished with value: 3532.799942529683 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 3.993100819117793, 'num_leaves': 92, 'n_estimators': 300, 'reg_alpha': 0.14191862316641715, 'learning_rate': 0.2808603219709367, 'feature_fraction': 0.438553559527927, 'bagging_fraction': 0.9573460379688669, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:19,963] Trial 75 finished with value: 3573.408279400984 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 7.354664252122555, 'num_leaves': 75, 'n_estimators': 281, 'reg_alpha': 0.061427937274249854, 'learning_rate': 0.2678554125070038, 'feature_fraction': 0.5623038688611486, 'bagging_fraction': 0.8906727694819571, 'bagging_freq': 7}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:23,363] Trial 76 finished with value: 3788.331667202682 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.1812020290796514, 'num_leaves': 98, 'n_estimators': 126, 'reg_alpha': 0.030994894845587345, 'learning_rate': 0.29295219835217856, 'feature_fraction': 0.5024024962797089, 'bagging_fraction': 0.9779126765374158, 'bagging_freq': 7}. Best is trial 60 with value: 3511.6738580527826.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:27,150] Trial 77 finished with value: 3648.292666825731 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.5748652640200058, 'num_leaves': 60, 'n_estimators': 192, 'reg_alpha': 0.07197621363259556, 'learning_rate': 0.27153981954262574, 'feature_fraction': 0.4626294694190594, 'bagging_fraction': 0.9280131397409738, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:31,406] Trial 78 finished with value: 3552.2150150668967 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 0.8117550475545473, 'num_leaves': 43, 'n_estimators': 292, 'reg_alpha': 0.14946701798651624, 'learning_rate': 0.2992276229742718, 'feature_fraction': 0.5306160106406099, 'bagging_fraction': 0.8507646172971259, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:35,692] Trial 79 finished with value: 3578.7736825935513 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 3.4409584530349537, 'num_leaves': 75, 'n_estimators': 263, 'reg_alpha': 0.21389236890819174, 'learning_rate': 0.2880113908436396, 'feature_fraction': 0.40012792027886224, 'bagging_fraction': 0.9582332414775242, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:39,972] Trial 80 finished with value: 3549.7653035031653 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.3946390966667337, 'num_leaves': 30, 'n_estimators': 283, 'reg_alpha': 0.12426608524338074, 'learning_rate': 0.280688597562605, 'feature_fraction': 0.5978837124220066, 'bagging_fraction': 0.8960588503864657, 'bagging_freq': 7}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:44,494] Trial 81 finished with value: 3514.7483055981693 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.8369202875724087, 'num_leaves': 51, 'n_estimators': 300, 'reg_alpha': 0.10205118293559749, 'learning_rate': 0.28692808948179405, 'feature_fraction': 0.49086042535075897, 'bagging_fraction': 0.9220930865064708, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:48,953] Trial 82 finished with value: 3539.55282157211 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.7956276699402123, 'num_leaves': 51, 'n_estimators': 294, 'reg_alpha': 0.0861577772146479, 'learning_rate': 0.2772558308316707, 'feature_fraction': 0.4812902481713089, 'bagging_fraction': 0.9381700144918727, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:53,528] Trial 83 finished with value: 3548.347098769533 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.6995013650540511, 'num_leaves': 59, 'n_estimators': 300, 'reg_alpha': 0.023754931861066034, 'learning_rate': 0.25057804819765395, 'feature_fraction': 0.43576997083645397, 'bagging_fraction': 0.9774860120791314, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:52:57,757] Trial 84 finished with value: 3562.617854498861 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 4.317596671829194, 'num_leaves': 73, 'n_estimators': 286, 'reg_alpha': 0.062474228582921246, 'learning_rate': 0.2721644840472244, 'feature_fraction': 0.5376366165016981, 'bagging_fraction': 0.9061333892673847, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:01,037] Trial 85 finished with value: 5633.242238827274 and parameters: {'boosting_type': 'gbdt', 'max_depth': 3, 'min_child_weight': 0.5791678312894617, 'num_leaves': 95, 'n_estimators': 278, 'reg_alpha': 0.11386779670581848, 'learning_rate': 0.08929074227537673, 'feature_fraction': 0.49227337724963915, 'bagging_fraction': 0.9467156890879205, 'bagging_freq': 7}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:05,411] Trial 86 finished with value: 3539.2273854673235 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.3691366608602147, 'num_leaves': 43, 'n_estimators': 291, 'reg_alpha': 0.7247737174567591, 'learning_rate': 0.29309032531327267, 'feature_fraction': 0.4576056739007935, 'bagging_fraction': 0.8607235748355274, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-27 07:53:09,541] Trial 87 finished with value: 3583.631872739247 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 6.945138667388189, 'num_leaves': 34, 'n_estimators': 264, 'reg_alpha': 0.08445525715142366, 'learning_rate': 0.2839872815632508, 'feature_fraction': 0.5641387915919431, 'bagging_fraction': 0.9800789761937719, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:12,782] Trial 88 finished with value: 3959.8013817463625 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 2.946126401136214, 'num_leaves': 68, 'n_estimators': 112, 'reg_alpha': 0.5003944574761069, 'learning_rate': 0.26322480105959634, 'feature_fraction': 0.43381125463595804, 'bagging_fraction': 0.8198829826096815, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:17,202] Trial 89 finished with value: 3794.9925492499874 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 0.7923020860038386, 'num_leaves': 47, 'n_estimators': 293, 'reg_alpha': 0.0540415824134293, 'learning_rate': 0.13243680694405235, 'feature_fraction': 0.5265639551639721, 'bagging_fraction': 0.907747496441427, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:21,488] Trial 90 finished with value: 3560.0204032112306 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 1.3683274379632249, 'num_leaves': 85, 'n_estimators': 280, 'reg_alpha': 0.19740986276388806, 'learning_rate': 0.29390722978380324, 'feature_fraction': 0.5034146868431497, 'bagging_fraction': 0.9413906106582659, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:25,921] Trial 91 finished with value: 3522.7412909039017 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.966316075249799, 'num_leaves': 80, 'n_estimators': 298, 'reg_alpha': 0.12741425954859914, 'learning_rate': 0.28603492770539907, 'feature_fraction': 0.4779662144977167, 'bagging_fraction': 0.9082627477222817, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:30,515] Trial 92 finished with value: 3526.841432453456 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 3.3025456635004953, 'num_leaves': 62, 'n_estimators': 300, 'reg_alpha': 0.12568680033623247, 'learning_rate': 0.2739372794491707, 'feature_fraction': 0.47476056225325053, 'bagging_fraction': 0.8736589030888239, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:34,987] Trial 93 finished with value: 3550.0240017781666 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.943726345751, 'num_leaves': 101, 'n_estimators': 284, 'reg_alpha': 0.02151990669669669, 'learning_rate': 0.283935219752415, 'feature_fraction': 0.4292939239176815, 'bagging_fraction': 0.9984467489080401, 'bagging_freq': 7}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:39,352] Trial 94 finished with value: 3529.3025092926373 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.6942504582607694, 'num_leaves': 89, 'n_estimators': 287, 'reg_alpha': 0.23395521483784015, 'learning_rate': 0.2995126009972332, 'feature_fraction': 0.4609082670283835, 'bagging_fraction': 0.9119505474778462, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:53:42,834] Trial 95 finished with value: 3729.6157753265 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 0.0011026821515783163, 'num_leaves': 77, 'n_estimators': 143, 'reg_alpha': 0.15300524300845716, 'learning_rate': 0.28960163635435826, 'feature_fraction': 0.4919264729301222, 'bagging_fraction': 0.966537710634808, 'bagging_freq': 5}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\callback.py:325: UserWarning: Early stopping is not available in dart mode\n",
            "  _log_warning('Early stopping is not available in dart mode')\n",
            "[I 2024-04-27 07:54:02,523] Trial 96 finished with value: 4038.766218073776 and parameters: {'boosting_type': 'dart', 'max_depth': 9, 'min_child_weight': 0.35260918252349766, 'num_leaves': 70, 'n_estimators': 296, 'reg_alpha': 0.4096209726882831, 'learning_rate': 0.254897848169268, 'feature_fraction': 0.5360044175768921, 'bagging_fraction': 0.8765804433343316, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:54:06,707] Trial 97 finished with value: 3585.7934948357906 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 9.593170330623375, 'num_leaves': 82, 'n_estimators': 268, 'reg_alpha': 0.18570785703748033, 'learning_rate': 0.2662916992803608, 'feature_fraction': 0.49433901468981944, 'bagging_fraction': 0.9345966360511627, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:54:11,148] Trial 98 finished with value: 3527.653360490426 and parameters: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 4.4481035192652145, 'num_leaves': 56, 'n_estimators': 295, 'reg_alpha': 0.08311321585189561, 'learning_rate': 0.280743739950744, 'feature_fraction': 0.45973242322474944, 'bagging_fraction': 0.9052972738735413, 'bagging_freq': 4}. Best is trial 60 with value: 3511.6738580527826.\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30792\\1091824998.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
            "[I 2024-04-27 07:54:15,246] Trial 99 finished with value: 3567.4440569980898 and parameters: {'boosting_type': 'gbdt', 'max_depth': 8, 'min_child_weight': 0.6703350567452003, 'num_leaves': 110, 'n_estimators': 277, 'reg_alpha': 0.1271372125306836, 'learning_rate': 0.2935608751850916, 'feature_fraction': 0.5537753598012293, 'bagging_fraction': 0.6281929582470613, 'bagging_freq': 6}. Best is trial 60 with value: 3511.6738580527826.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of finished trials: 100\n",
            "Best trial: {'boosting_type': 'gbdt', 'max_depth': 9, 'min_child_weight': 1.1431893137969014, 'num_leaves': 82, 'n_estimators': 299, 'reg_alpha': 0.0989510274808229, 'learning_rate': 0.28657822394928195, 'feature_fraction': 0.4802099728688999, 'bagging_fraction': 0.9194624540707252, 'bagging_freq': 6}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def para(trial):\n",
        "    boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss'])\n",
        "    param = {\n",
        "        'boosting_type': boosting_type,\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-3, 10),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "\n",
        "    }\n",
        "\n",
        "    if boosting_type != 'goss':\n",
        "        param['feature_fraction'] = trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
        "        param['bagging_fraction'] = trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
        "        param['bagging_freq'] = trial.suggest_int('bagging_freq', 1, 7)\n",
        "\n",
        "    modelo = lgb.LGBMRegressor(**param, early_stopping_rounds=50, verbose=-1)\n",
        "    modelo.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
        "    preds = modelo.predict(X_test)\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    return rmse\n",
        "\n",
        "revision= optuna.create_study(direction='minimize')\n",
        "revision.optimize(para, n_trials=100)\n",
        "\n",
        "print('Number of finished trials:', len(revision.trials))\n",
        "print('Best trial:', revision.best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b6c41e",
      "metadata": {
        "id": "b2b6c41e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb49fbfa",
      "metadata": {
        "id": "fb49fbfa",
        "outputId": "51c415a0-cc95-43a0-cf6f-480393df573d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE) con LightGBM: 12331853.285331314\n",
            "Root Mean Squared Error (RMSE) con LightGBM: 3511.6738580527826\n",
            "R\" con LightGBM: 0.892812427605935\n"
          ]
        }
      ],
      "source": [
        "#opcion LightGBM\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Inicializar el estimador con LightGBM\n",
        "estima = lgb.LGBMRegressor()\n",
        "\n",
        "# Preparar el conjunto de datos en el formato de LightGBM\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# Configurar los parámetros del modelo\n",
        "paramsLG = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'max_depth': 9,\n",
        "    'min_child_weight': 1.1431893137969014,\n",
        "    'num_leaves': 82,\n",
        "    'n_estimators': 299,\n",
        "    'reg_alpha':0.0989510274808229,\n",
        "    'learning_rate': 0.28657822394928195,\n",
        "    'feature_fraction': 0.4802099728688999,\n",
        "    'bagging_fraction': 0.9194624540707252,\n",
        "    'bagging_freq': 6,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Entrenar el modelo\n",
        "gbm = lgb.train(paramsLG,\n",
        "                train_data,\n",
        "                num_boost_round=10000,\n",
        "                valid_sets=valid_data)\n",
        "\n",
        "# Predecir\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# Evaluar con MSE y RMSE\n",
        "mse_lgb_rfe = mean_squared_error(y_test, y_pred)\n",
        "rmse_lgb_rfe = sqrt(mse_lgb_rfe)\n",
        "r2LG = r2_score(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE) con LightGBM: {mse_lgb_rfe}')\n",
        "print(f'Root Mean Squared Error (RMSE) con LightGBM: {rmse_lgb_rfe}')\n",
        "print(f'R\" con LightGBM: {r2LG}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1fb041",
      "metadata": {
        "id": "ac1fb041"
      },
      "source": [
        "Dado que LightGBM es un modelo de rapida ejecucion,  procederemos a ajustar algunos hiperparamentros de forma artesanal y verificar si los podemos mejorar partiendo de la base que optuna genero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d200b16",
      "metadata": {
        "id": "6d200b16",
        "outputId": "534f5124-b5c5-477f-b69d-ccaa169e67e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE) con LightGBM: 11681315.104957476\n",
            "Root Mean Squared Error (RMSE) con LightGBM: 3417.793894452601\n",
            "R\" con LightGBM: 0.8984668581842542\n"
          ]
        }
      ],
      "source": [
        "#opcion LightGBM\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Inicializar el estimador con LightGBM\n",
        "estima = lgb.LGBMRegressor()\n",
        "\n",
        "# Preparar el conjunto de datos en el formato de LightGBM\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# Configurar los parámetros del modelo\n",
        "paramsLG = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'max_depth': 3,\n",
        "    'min_child_weight': 0.02,\n",
        "    'num_leaves': 64,\n",
        "    'n_estimators': 13000,\n",
        "    'reg_alpha':1,\n",
        "\n",
        "    'learning_rate': 0.2,\n",
        "    'feature_fraction': 1,\n",
        "    'bagging_fraction': 1,\n",
        "    'bagging_freq': 8,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Entrenar el modelo\n",
        "gbm = lgb.train(paramsLG,\n",
        "                train_data,\n",
        "                num_boost_round=10000,\n",
        "                valid_sets=valid_data)\n",
        "\n",
        "# Predecir\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# Evaluar con MSE y RMSE\n",
        "mse_lgb_rfe = mean_squared_error(y_test, y_pred)\n",
        "rmse_lgb_rfe = sqrt(mse_lgb_rfe)\n",
        "r2LG = r2_score(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE) con LightGBM: {mse_lgb_rfe}')\n",
        "print(f'Root Mean Squared Error (RMSE) con LightGBM: {rmse_lgb_rfe}')\n",
        "print(f'R\" con LightGBM: {r2LG}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4eaf378",
      "metadata": {
        "id": "d4eaf378"
      },
      "source": [
        "Despues de la calibracion por optuna y posteriormente la calibracion manual, 3417,79 es el mejor resultado obtenido, a continuacion se explicara que implica cada parametro:\n",
        "\n",
        "\n",
        "boosting_type: gbdt, Gradient Boosting Decision Tree, utiliza árboles de decisión como base learners.\n",
        "\n",
        "max_depth: limita la máxima profundidad de los árboles, ayuda a controlar el sobreajuste ya que árboles más profundos pueden aprender detalles más finos de los datos de entrenamiento.\n",
        "\n",
        "min_child_weight: es el peso mínimo de todas las observaciones requeridas en un nodo hijo, se uso para controlar el sobreajuste cuanto mayor es el valor, más conservador será el algoritmo.\n",
        "\n",
        "\n",
        "num_leaves: Es el número de hojas que un árbol puede tener como máximo, en LightGBM, es un parámetro crucial ya que controla la complejidad del modelo, un número más grande permitirá al modelo ajustar los datos con mayor precisión pero también puede llevar a sobreajuste.\n",
        "\n",
        "n_estimators: número de árboles de boosting que se construirán, este es un parámetro importante porque un número mayor de árboles puede mejorar la precisión, pero también puede causar sobreajuste.\n",
        "\n",
        "reg_alpha: también conocido como el término de regularización L1, que se usa para poner penalizacion en la magnitud de los coeficientes de las características y así controlar el sobreajuste.\n",
        "\n",
        "learning_rate: tasa de aprendizaje, afecta la contribución de cada árbol al modelo final, un valor más bajo requiere más árboles para ser efectivo, pero generalmente mejora la generalización del modelo.\n",
        "\n",
        "feature_fraction: fracción de características que se seleccionarán aleatoriamente para cada iteración (cada arbol), permite a LightGBM construir árboles más diversificados y puede ayudar a evitar el sobreajuste.\n",
        "\n",
        "bagging_fraction: fracción de datos que se usará para cada iteración de árboles, reduce el riesgo de sobreajuste al introducir más aleatoriedad durante la creación de los datos de entrenamiento para cada árbol.\n",
        "\n",
        "bagging_freq: frecuencia de muestreo de bolsas, indica cada cuántas iteraciones se debe realizar el muestreo de bolsas\n",
        "\n",
        "verbose: Controla la cantidad de salida que el modelo produce durante el entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c5df1ab",
      "metadata": {
        "id": "0c5df1ab"
      },
      "source": [
        "__________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdead843",
      "metadata": {
        "id": "fdead843"
      },
      "source": [
        "hasta este punto LightGBM es el mejor modelo, ahora intentaremos mejorar la prediccion con un ensamble de XGboos, LightGBM, Random Forest como base y un meta-modelo final como regresion lineal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065de925",
      "metadata": {
        "id": "065de925",
        "outputId": "b046fa38-35d1-43a3-9af3-0c17766c8275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE) con Stacking: 11556561.86867444\n",
            "Root Mean Squared Error (RMSE) con Stacking: 3399.4943548525625\n",
            "R^2 con Stacking: 0.8995512042461221\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# definir los modelos base\n",
        "estimators = [\n",
        "    ('lgbm', lgb.LGBMRegressor(\n",
        "        boosting_type='gbdt',\n",
        "        objective='regression',\n",
        "        metric='rmse',\n",
        "        max_depth=3,\n",
        "        min_child_weight=0.02,\n",
        "        num_leaves=64,\n",
        "        n_estimators=13000,\n",
        "        reg_alpha=1,\n",
        "        learning_rate=0.2,\n",
        "        feature_fraction=1,\n",
        "        bagging_fraction=1,\n",
        "        bagging_freq=8,\n",
        "        verbose=-1,\n",
        "        n_jobs=-1\n",
        "    )),\n",
        "    ('xgb', xgb.XGBRegressor(\n",
        "        n_estimators=700,\n",
        "        max_depth=10,\n",
        "        learning_rate=0.2,\n",
        "        subsample=0.999,\n",
        "        colsample_bytree=0.999,\n",
        "        min_child_weight=6,\n",
        "        gamma=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )),\n",
        "     ('rf', RandomForestRegressor(\n",
        "         random_state=42,\n",
        "         n_jobs=-1\n",
        "    ))\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# definir el meta-modelo\n",
        "final_estimator = LinearRegression()\n",
        "\n",
        "# crear el modelo de stacking\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=final_estimator,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# entrenar el modelo de stacking\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones con el modelo de stacking\n",
        "y_pred_stack = stacking_model.predict(X_test)\n",
        "\n",
        "# evaluar el modelo de stacking\n",
        "mse_stack = mean_squared_error(y_test, y_pred_stack)\n",
        "rmse_stack = sqrt(mse_stack)\n",
        "r2_stack = r2_score(y_test, y_pred_stack)\n",
        "\n",
        "# mostrar resultados\n",
        "print(f'Mean Squared Error (MSE) con Stacking: {mse_stack}')\n",
        "print(f'Root Mean Squared Error (RMSE) con Stacking: {rmse_stack}')\n",
        "print(f'R^2 con Stacking: {r2_stack}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d11599",
      "metadata": {
        "id": "f6d11599"
      },
      "source": [
        "\n",
        "El precio de los vehículos utilizando un modelo de stacking con LightGBM, XGBoost y RandomForest como modelos base, y una regresión lineal como meta-modelo, es una estrategia que mejora el RMSE en cerca de 16 puntos, lo cual es clave para temas de competencia y prediccion,  esta forma  captura la fuerza de varios modelos diferentes y combinar sus predicciones para obtener un resultado más preciso.\n",
        "\n",
        "Utilizar una regresión lineal como meta-modelo es una elecció efectiva para combinar las predicciones de los modelos base, ya que asigna pesos a las predicciones de cada modelo base para minimizar el error."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b4433b",
      "metadata": {
        "id": "d4b4433b"
      },
      "source": [
        "____________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb8dc14",
      "metadata": {
        "id": "beb8dc14",
        "outputId": "4672bf46-fbc9-46a1-fef6-8a2a034e6437"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21136.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36771.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23481.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8067.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30521.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Price\n",
              "ID         \n",
              "0  21136.22\n",
              "1  36771.43\n",
              "2  23481.69\n",
              "3   8067.06\n",
              "4  30521.08"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# kaggle\n",
        "\n",
        "# cargar los conjuntos de entrenamiento y prueba\n",
        "train_data = dataTraining\n",
        "test_data = dataTesting\n",
        "\n",
        "# preparar las variables independientes y la variable objetivo\n",
        "X_train = train_data.drop(['Price'], axis=1)\n",
        "y_train = train_data['Price']\n",
        "\n",
        "# definir los modelos base\n",
        "estimators = [\n",
        "    ('lgbm', lgb.LGBMRegressor(\n",
        "        boosting_type='gbdt',\n",
        "        objective='regression',\n",
        "        metric='rmse',\n",
        "        max_depth=3,\n",
        "        min_child_weight=0.02,\n",
        "        num_leaves=64,\n",
        "        n_estimators=13000,\n",
        "        reg_alpha=1,\n",
        "        learning_rate=0.2,\n",
        "        feature_fraction=1,\n",
        "        bagging_fraction=1,\n",
        "        bagging_freq=8,\n",
        "        verbose=-1,\n",
        "        n_jobs=-1\n",
        "    )),\n",
        "    ('xgb', xgb.XGBRegressor(\n",
        "        n_estimators=700,\n",
        "        max_depth=10,\n",
        "        learning_rate=0.2,\n",
        "        subsample=0.999,\n",
        "        colsample_bytree=0.999,\n",
        "        min_child_weight=6,\n",
        "        gamma=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )),\n",
        "     ('rf', RandomForestRegressor(\n",
        "         n_estimators=100,\n",
        "         random_state=42,\n",
        "         n_jobs=-1\n",
        "    ))\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Definir el meta-modelo\n",
        "final_estimator = LinearRegression(n_jobs=-1)\n",
        "\n",
        "# crear el modelo de stacking\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=final_estimator,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# entrenar el modelo de stacking\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "X_testkaggle = test_data\n",
        "y_pred_testkaggle = stacking_model.predict(X_testkaggle)\n",
        "\n",
        "\n",
        "submission_df = pd.DataFrame(y_pred_testkaggle, index=dataTesting.index, columns=['Price'])\n",
        "\n",
        "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
        "submission_df.to_csv('Gio_final.csv', index_label='ID')\n",
        "submission_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0e8431",
      "metadata": {
        "id": "ce0e8431",
        "outputId": "1dbbdc72-5a7c-4ef0-92aa-49ad88529be1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCkAAAGYCAYAAABvWLgQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABWgUlEQVR4nO3deXwO5/7/8fedVUhyE5GtImgtaS09xSHaYxe0RKtK0aC2qqKprdWNtojqUXoodXoQa1NaS1vEUlvV7ivHUlXVKNFELJGIJev8/ugvUxFUNE5GvJ6PxzweuWc+98w1ae8xed/XXJfNMAxDAAAAAAAARcyhqBsAAAAAAAAgEVIAAAAAAACLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAACAQhEVFSWbzWYuTk5O8vf317PPPqsjR47kqW3SpIlsNpsqV64swzDy7Wvz5s3mfqKiovJs27Fjh5566ilVqFBBrq6u8vX1VUhIiIYOHXrdY1xvqVixYmGfPgAAKARORd0AAABQvMyePVvVq1fXlStX9P3332vs2LHasGGDfvzxR5UpU8as8/DwUFxcnNavX6/mzZvn2cesWbPk6emp1NTUPOtXrFihsLAwNWnSRBMmTJC/v78SEhK0e/duRUdHa+LEiXnqK1eurAULFuRro6urayGeMQAAKCyEFAAAoFDVqFFDdevWlfR7b4bs7GyNGjVKy5Yt0/PPP2/WVahQQR4eHpo1a1aekOLChQtavHixunXrpk8//TTPvidMmKBKlSpp9erVcnL64zbm2Wef1YQJE/K1xc3NTQ0aNCjsUwQAAHcIj3sAAIA7KjewOHXqVL5tvXr10pIlS3T+/HlzXXR0tKTfg4drnT17Vt7e3nkCilwODtzWAABwt+NfcwAAcEfFxcVJkqpWrZpv27PPPitHR0d99tln5rqZM2eqY8eO8vT0zFcfEhKiHTt2aPDgwdqxY4cyMzP/9PhZWVn5lpycnL9wRgAA4E4hpAAAAIUqOztbWVlZSktL0+rVqzVmzBg1atRIYWFh+Wo9PDzUsWNHzZo1S5L0ww8/aMeOHerVq9d19z1+/Hg99thjmjJliho0aKBSpUrp0Ucf1fjx45WWlpav/uDBg3J2ds639OvXr3BPGgAAFArGpAAAAIXq2jEggoODtXz58us+oiH9/shH48aNtX//fkVFRen+++9Xo0aNtGfPnny1ZcuW1Xfffafdu3fr22+/1e7du7Vx40aNHDlSM2bM0K5du+Tt7W3W33///ebjI1crV67cXzxLAABwJxBSAACAQjV37lwFBwfrwoUL+vzzzzVjxgx16dJFq1atum59o0aNVKVKFc2YMUOLFi1SRESEbDbbTY9Rt25dc6yLzMxMvfrqq5o0aZImTJiQZwDNEiVKmHUAAMD6eNwDAAAUquDgYNWtW1dNmzbVJ598oj59+igmJkZffPHFDd/z/PPPa/r06Tp37px69OhRoOM5Oztr1KhRkqQDBw78pbYDAICiRUgBAADuqAkTJqhMmTJ6++23bzhgZY8ePdSuXTsNHz5c99133w33lZCQcN31hw4dkiQFBAT89QYDAIAiw+MeAADgjipTpoxGjhypESNGaOHChXruuefy1QQEBGjZsmV/uq9WrVqpfPnyateunapXr66cnBzFxsZq4sSJcnd318svv5yn/vLly9q+fft193Xt2BkAAKDoEVIAAIA7btCgQZo6dareffdddenS5bb38+abb2r58uWaNGmSEhISlJ6eLn9/f7Vo0UIjR45UcHBwnvpffvlFISEh191XZmbmDQfzBAAARcNmGIZR1I0AAAAAAABgTAoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsodhODp6Tk6PffvtNHh4estlsRd0cAAAAAADuSYZh6MKFCwoICJCDw837ShTbkOK3335TYGBgUTcDAAAAAABIOnHihMqXL3/TmmIbUnh4eEj6/Zfg6elZxK0BAAAAAODelJqaqsDAQPPv9JsptiFF7iMenp6ehBQAAAAAABSxWxmKgYEzAQAAAACAJRBSAAAAAAAASyhQSDF9+nTVqlXLfIQiJCREq1atMrf37NlTNpstz9KgQYM8+0hPT9egQYPk7e2tUqVKKSwsTPHx8XlqkpOTFR4eLrvdLrvdrvDwcJ0/f/72zxK4S/3ZZ+5qL7zwgmw2myZPnnzd7YZhqE2bNrLZbFq2bFmebWFhYapQoYJKlCghf39/hYeH67fffrvldt7o2C+88ILuv/9+ubm5qVy5cmrfvr1+/PHHPDX/93//p5YtW6p06dIqW7as+vXrp7S0tDw1L7/8surUqSNXV1c9/PDDt9wuAAAAAHeXAoUU5cuX1/jx47V7927t3r1bzZo1U/v27XXw4EGzpnXr1kpISDCXlStX5tlHRESEli5dqujoaG3ZskVpaWlq27atsrOzzZquXbsqNjZWMTExiomJUWxsrMLDw//iqQJ3n1v5zEnSsmXLtGPHDgUEBNxwX5MnT77hM2BNmzbVokWLdPjwYX355Zc6evSoOnbseEttvNmx69Spo9mzZ+vQoUNavXq1DMNQaGio+Xn/7bff1KJFCz3wwAPasWOHYmJidPDgQfXs2TPPfgzDUK9evdS5c+dbahMAAACAu5TxF5UpU8b4z3/+YxiGYfTo0cNo3779DWvPnz9vODs7G9HR0ea6kydPGg4ODkZMTIxhGIbxww8/GJKM7du3mzXbtm0zJBk//vjjLbcrJSXFkGSkpKQU8IwAa7v6M2cYhhEfH2/cd999xoEDB4ygoCBj0qRJ+d4TGxtrlC9f3khISDAkGUuXLr3pMZYvX27YbDYjIyPjpnW3cuyr/fe//zUkGT///LNhGIYxY8YMw8fHx8jOzjZr9u7da0gyjhw5ku/9o0aNMmrXrn3TYwAonqZNm2bUrFnT8PDwMDw8PIwGDRoYK1euvG5tv379DEn5rkkzZswwGjdubHh4eBiSjOTk5DzbN2zYYEi67rJz584btu1G75kwYYJZ8/PPPxtPPvmk4e3tbXh4eBjPPPOMkZiYmGc/7dq1MwIDAw1XV1fDz8/PeO6554yTJ0/mqVm3bp0REhJiuLu7G35+fsaIESOMzMzMW/gNAgBQdAry9/ltj0mRnZ2t6OhoXbx4USEhIeb6jRs3ysfHR1WrVlXfvn2VlJRkbtuzZ48yMzMVGhpqrgsICFCNGjW0detWSdK2bdtkt9tVv359s6ZBgway2+1mDXAvut5nLicnR+Hh4Ro+fLgeeuih677v0qVL6tKli6ZOnSo/P78/Pc65c+e0YMECNWzYUM7Ozjesu5VjX+3ixYuaPXu2KlWqpMDAQEm/P/7l4uIiB4c/LkVubm6SpC1btvzpPgHcOwqjZ9mlS5fUunVrvf7669c9RsOGDfP0Bk1ISFCfPn1UsWJF1a1b94Ztu/Y9s2bNks1m09NPPy3p9+tfaGiobDab1q9fr++//14ZGRlq166dcnJyzP38Wa+2ffv26fHHH1fr1q21d+9eRUdH66uvvtJrr71WoN8lgLvfnz0SPHr0aFWvXl2lSpVSmTJl1KJFC+3YsSPPPo4ePaqnnnpK5cqVk6enpzp16qRTp07lqbmVx3Jv5kaPBN/KsXOlp6fr4Ycfls1mU2xs7HVrzp49q/Lly8tmszFMQDFQ4JBi//79cnd3l6urq/r376+lS5fqwQcflCS1adNGCxYs0Pr16zVx4kTt2rVLzZo1U3p6uiQpMTFRLi4uKlOmTJ59+vr6KjEx0azx8fHJd1wfHx+z5nrS09OVmpqaZwGKg5t95t5//305OTlp8ODBN3z/K6+8ooYNG6p9+/Y3Pc6rr76qUqVKqWzZsjp+/LiWL19+0/pbObYkTZs2Te7u7nJ3d1dMTIzWrl0rFxcXSVKzZs2UmJioDz74QBkZGUpOTjb/eEhISLjpfgHcW9q1a6fHH39cVatWVdWqVTV27Fi5u7tr+/btZs3Jkyc1cOBALViw4Loha0REhF577bV842XlcnFxkZ+fn7mULVtWX331lXr16nXTKdOufo+fn5+WL1+upk2bqnLlypKk77//XseOHVNUVJRq1qypmjVravbs2dq1a5fWr19v7ueVV15RgwYNFBQUpIYNG+q1117T9u3blZmZKUmKjo5WrVq19Pbbb+uBBx5Q48aNFRkZqY8//lgXLly4rd8rgLvTnwW3VatW1dSpU7V//35t2bJFFStWVGhoqE6fPi3p1sLTW30s90ZuFBrfanCba8SIETd9pFmSevfurVq1at1Su2B9BQ4pqlWrptjYWG3fvl0vvviievTooR9++EGS1LlzZz3xxBOqUaOG2rVrp1WrVumnn37SihUrbrpPwzDy/ON/vRuBa2uuFRkZaQ60abfbzW9qgbvdjT5ze/bs0UcffaSoqKgbfja++uorrV+//oaDaV5t+PDh2rt3r9asWSNHR0d1795dhmFct/ZWjp2rW7du2rt3rzZt2qQqVaqoU6dOunLliiTpoYce0pw5czRx4kSVLFlSfn5+qly5snx9feXo6PinbQZwb7rdnmUF9dVXX+nMmTO3fEMuSadOndKKFSvUu3dvc116erpsNptcXV3NdSVKlJCDg8MNe41dr1dbenq6SpQokafOzc1NV65c0Z49ewpwZgDudn8W3Hbt2lUtWrRQ5cqV9dBDD+nDDz9Uamqq9u3bJ+nWwtNvvvlGzs7O+vjjj1WtWjXVq1dPH3/8sb788kv9/PPPN23fzULjWw1uJWnVqlVas2aN/vnPf97wWNOnT9f58+c1bNiwAv8eYU0FDilcXFz0wAMPqG7duoqMjFTt2rX10UcfXbfW399fQUFBOnLkiKTfv2nI/bb0aklJSfL19TVrrtfV5/Tp02bN9YwcOVIpKSnmcuLEiYKeGmBJN/rMfffdd0pKSlKFChXk5OQkJycn/frrrxo6dKgqVqwoSVq/fr2OHj2q0qVLmzWS9PTTT6tJkyZ5juPt7a2qVauqZcuWio6O1sqVK/N8Q3m1Wzl2LrvdripVqqhRo0b64osv9OOPP2rp0qXm9q5duyoxMVEnT57U2bNnNXr0aJ0+fVqVKlUqtN8hgOLhr/YsK6iZM2eqVatWBfriY86cOfLw8FCHDh3MdQ0aNFCpUqX06quv6tKlS7p48aKGDx+unJycfL3GbtarrVWrVtq6das+++wzZWdn6+TJkxozZowkep8B97IbPYafKyMjQ//+979lt9tVu3ZtSbcWnt7uY7l/FhrfanB76tQp9e3bV/PmzVPJkiWve6wffvhB7777rubOnZunnbi7/eX/koZhmI9zXOvs2bM6ceKE/P39Jf0+0r+zs7PWrl1r1iQkJOjAgQNq2LChJCkkJEQpKSnauXOnWbNjxw6lpKSYNdfj6upqPpOVuwDFUe5nLjw8XPv27VNsbKy5BAQEaPjw4Vq9erUk6bXXXstXI0mTJk3S7Nmzb3oMSTf8bN/Ksf+s/dfy9fWVu7u7Pv/8c5UoUUItW7a8lV8HgHvIX+lZVlDx8fFavXp1nh4Rt2LWrFnq1q1bnh4P5cqV0+LFi/X111/L3d1ddrtdKSkpeuSRR/L1GrtZr7bQ0FB98MEH6t+/v1xdXVW1alU98cQTkkTvM+AedLPgVvq9J4S7u7tKlCihSZMmae3atfL29pZ0a+Hp7T6W+2eh8a0c2zAM9ezZU/3797/hmEDp6enq0qWLPvjgA1WoUKHgv0BYV0FG5Bw5cqSxefNmIy4uzti3b5/x+uuvGw4ODsaaNWuMCxcuGEOHDjW2bt1qxMXFGRs2bDBCQkKM++67z0hNTTX30b9/f6N8+fLGunXrjP/7v/8zmjVrZtSuXdvIysoya1q3bm3UqlXL2LZtm7Ft2zajZs2aRtu2bQvSVGb3QLFws8/c9dzKDBu6ZnaPHTt2GFOmTDH27t1rHDt2zFi/fr3x2GOPGffff79x5coVs65atWrGkiVLbrjfa4999OhRY9y4ccbu3buNX3/91di6davRvn17w8vLyzh16pRZN2XKFGPPnj3G4cOHjalTpxpubm7GRx99lGffR44cMfbu3Wu88MILRtWqVY29e/cae/fuNdLT0296rgCKt+bNmxv9+vUzJk2aZNhsNsPR0dFcJBkODg5GUFBQvvflzuJx7eweV3v33XeNcuXK/eksR1fbvHmzIcmIjY29Yc3p06fN4/r6+uaZAeRaJ06cMCQZW7duzbM+JyfHOHnypHHp0iVzVrSbzT4CoHhKT083jhw5Yuzatct47bXXDG9vb+PgwYPm9rS0NOPIkSPGtm3bjF69ehkVK1bMcw+2evVqo3Llyub187nnnjMeeeQR48UXXzRrFixYYPj6+hqOjo6Gi4uLMWzYMMPX19d4//33r9um3bt3G76+vnlmJrre/emfHfujjz4yGjZsaP6NGBcXZ0gy9u7da+7jlVdeMTp37my+vpVrO4pOQf4+L1BI0atXLyMoKMhwcXExypUrZzRv3tz8Y+nSpUtGaGioUa5cOcPZ2dmoUKGC0aNHD+P48eN59nH58mVj4MCBhpeXl+Hm5ma0bds2X83Zs2eNbt26mdOMdevWrcD/sxFSoDi42Wfuem4npNi3b5/RtGlTw8vLy3B1dTUqVqxo9O/f34iPj8/3vtmzZ9/ysU+ePGm0adPG8PHxMZydnY3y5csbXbt2zTeVcHh4uOHl5WW4uLgYtWrVMubOnZtv340bN77u9H5xcXE3PVcAxVuzZs2MHj16GGfOnDH279+fZwkICDBeffXV605f/mc3sjk5OUalSpWMoUOHFqg9PXr0MOrUqXNLtd9++61hs9luOr368ePHDUnGhg0bbljz1ltvGYGBgXm+7AFwb8oNbm/kgQceMMaNG5dv/a2Ep4mJicaFCxeMtLQ0w8HBwVi0aNF1j1HQ0PhGx27fvr3h4OCQbz+Ojo5G9+7dDcMwjNq1a+epcXBwMGvefvvtm/2qUAQK8ve5zTBuMDLeXS41NdXsTnm3PfpR8bWbDzQK4N5wbPwTRd0EwDJef/11tWnTRoGBgbpw4YKio6M1fvx4xcTEXPfxsIoVKyoiIkIRERHmusTERCUmJmr37t3q27evNm/eLA8PD1WoUEFeXl5m3bfffqsWLVrohx9+UHBwcL59V69eXZGRkXrqqafMdampqfL399fEiRPVv3//fO+ZPXu2goODVa5cOW3btk0vv/yyevbsqYkTJ0qSdu7cqZ07d+qxxx5TmTJl9Msvv+jtt99WQkKCDh48aD67/cEHH6h169ZycHDQkiVL9N5772nRokV68sknb/dXC6CYaN68uQIDAxUVFXXd7Q888ICee+45jR49+rrb169frxYtWujQoUOqVq3adWtmzZqlQYMG6eTJkypdunS+7WfPns33KEirVq0UHh6u559//ob7vfbYx48fzzNb42+//aZWrVrpiy++UP369VW+fHkdPXpUly9fNmt27dqlXr16aevWrbr//vuvO2Mkik5B/j53+h+1CQAA4LadOnVK4eHhSkhIkN1uV61atW4YUNzIJ598onfeecd83ahRI0m/BwhXz+Axc+ZMNWzY8LoBhSQdPnxYKSkpedZFR0fLMAx16dLlhu8ZOXKkzp07p4oVK+qNN97QK6+8Ym53c3PTkiVLNGrUKF28eFH+/v5q3bq1oqOj8wwut2rVKo0dO1bp6emqXbu2li9frjZt2tzy7wBA8XC94Hbjxo2KiYnRxYsXNXbsWIWFhcnf319nz57VtGnTFB8fr2eeecbcx/XC01deeSVPkDB16lQ1bNhQ7u7uWrt2rYYPH67x48fnCSiuDm7Lli2rsmXL5mmrs7Oz/Pz88uz3z4597RgT7u7ukqT7779f5cuXN3++2pkzZyRJwcHB1w1QcPegJ4UF0ZMCgERPConrIYA/cE0E/tC7d299++23eYLbV199VS1bttSVK1fUtWtX7dixQ2fOnFHZsmVVr149vfnmm6pXr565j9dee01RUVFmeNq/f3+98soreQYg7t69u1asWKG0tDRVr15dw4YNU3h4eJ622Gy2fGHv1a7Xs+1Wjn21Y8eOqVKlStq7d68efvjh69Zs3LhRTZs2VXJyMiGFBRXk73NCCgviphyAxA25xPUQwB+4JnJNBPCHu+2aWJC/z5lMFgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIKFFJMnz5dtWrVkqenpzw9PRUSEqJVq1aZ2w3D0OjRoxUQECA3Nzc1adJEBw8ezLOP9PR0DRo0SN7e3ipVqpTCwsIUHx+fpyY5OVnh4eGy2+2y2+0KDw/X+fPnb/8sAQAAAACA5RUopChfvrzGjx+v3bt3a/fu3WrWrJnat29vBhETJkzQhx9+qKlTp2rXrl3y8/NTy5YtdeHCBXMfERERWrp0qaKjo7VlyxalpaWpbdu2ys7ONmu6du2q2NhYxcTEKCYmRrGxsQoPDy+kUwYAAAAAAFbkVJDidu3a5Xk9duxYTZ8+Xdu3b9eDDz6oyZMn64033lCHDh0kSXPmzJGvr68WLlyoF154QSkpKZo5c6bmzZunFi1aSJLmz5+vwMBArVu3Tq1atdKhQ4cUExOj7du3q379+pKkTz/9VCEhITp8+LCqVatWGOcNAAAAAAAs5rbHpMjOzlZ0dLQuXryokJAQxcXFKTExUaGhoWaNq6urGjdurK1bt0qS9uzZo8zMzDw1AQEBqlGjhlmzbds22e12M6CQpAYNGshut5s115Oenq7U1NQ8CwAAAAAAuHsUOKTYv3+/3N3d5erqqv79+2vp0qV68MEHlZiYKEny9fXNU+/r62tuS0xMlIuLi8qUKXPTGh8fn3zH9fHxMWuuJzIy0hzDwm63KzAwsKCnBgAAAAAAilCBQ4pq1aopNjZW27dv14svvqgePXrohx9+MLfbbLY89YZh5Ft3rWtrrlf/Z/sZOXKkUlJSzOXEiRO3ekoAAAAAAMACChxSuLi46IEHHlDdunUVGRmp2rVr66OPPpKfn58k5evtkJSUZPau8PPzU0ZGhpKTk29ac+rUqXzHPX36dL5eGldzdXU1Zx3JXQAAAAAAwN3jtsekyGUYhtLT01WpUiX5+flp7dq15raMjAxt2rRJDRs2lCTVqVNHzs7OeWoSEhJ04MABsyYkJEQpKSnauXOnWbNjxw6lpKSYNQAAAAAAoPgp0Ower7/+utq0aaPAwEBduHBB0dHR2rhxo2JiYmSz2RQREaFx48apSpUqqlKlisaNG6eSJUuqa9eukiS73a7evXtr6NChKlu2rLy8vDRs2DDVrFnTnO0jODhYrVu3Vt++fTVjxgxJUr9+/dS2bVtm9gAAAAAAoBgrUEhx6tQphYeHKyEhQXa7XbVq1VJMTIxatmwpSRoxYoQuX76sAQMGKDk5WfXr19eaNWvk4eFh7mPSpElycnJSp06ddPnyZTVv3lxRUVFydHQ0axYsWKDBgwebs4CEhYVp6tSphXG+AAAAAADAomyGYRhF3Yg7ITU1VXa7XSkpKXfd+BQVX1tR1E0AYAHHxj9R1E0oclwPAeTimsg1EcAf7rZrYkH+Pv/LY1IAAAAAAAAUBkIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAllCgkCIyMlL16tWTh4eHfHx89OSTT+rw4cN5anr27CmbzZZnadCgQZ6a9PR0DRo0SN7e3ipVqpTCwsIUHx+fpyY5OVnh4eGy2+2y2+0KDw/X+fPnb+8sAQAAAACA5RUopNi0aZNeeuklbd++XWvXrlVWVpZCQ0N18eLFPHWtW7dWQkKCuaxcuTLP9oiICC1dulTR0dHasmWL0tLS1LZtW2VnZ5s1Xbt2VWxsrGJiYhQTE6PY2FiFh4f/hVMFAAAAAABW5lSQ4piYmDyvZ8+eLR8fH+3Zs0eNGjUy17u6usrPz++6+0hJSdHMmTM1b948tWjRQpI0f/58BQYGat26dWrVqpUOHTqkmJgYbd++XfXr15ckffrppwoJCdHhw4dVrVq1Ap0kAAAAAACwvr80JkVKSookycvLK8/6jRs3ysfHR1WrVlXfvn2VlJRkbtuzZ48yMzMVGhpqrgsICFCNGjW0detWSdK2bdtkt9vNgEKSGjRoILvdbtYAAAAAAIDipUA9Ka5mGIaGDBmixx57TDVq1DDXt2nTRs8884yCgoIUFxent956S82aNdOePXvk6uqqxMREubi4qEyZMnn25+vrq8TERElSYmKifHx88h3Tx8fHrLlWenq60tPTzdepqam3e2oAAAAAAKAI3HZIMXDgQO3bt09btmzJs75z587mzzVq1FDdunUVFBSkFStWqEOHDjfcn2EYstls5uurf75RzdUiIyP1zjvvFPQ0AAAAAACARdzW4x6DBg3SV199pQ0bNqh8+fI3rfX391dQUJCOHDkiSfLz81NGRoaSk5Pz1CUlJcnX19esOXXqVL59nT592qy51siRI5WSkmIuJ06cuJ1TAwAAAAAARaRAIYVhGBo4cKCWLFmi9evXq1KlSn/6nrNnz+rEiRPy9/eXJNWpU0fOzs5au3atWZOQkKADBw6oYcOGkqSQkBClpKRo586dZs2OHTuUkpJi1lzL1dVVnp6eeRYAAAAAAHD3KNDjHi+99JIWLlyo5cuXy8PDwxwfwm63y83NTWlpaRo9erSefvpp+fv769ixY3r99dfl7e2tp556yqzt3bu3hg4dqrJly8rLy0vDhg1TzZo1zdk+goOD1bp1a/Xt21czZsyQJPXr109t27ZlZg8AAAAAAIqpAoUU06dPlyQ1adIkz/rZs2erZ8+ecnR01P79+zV37lydP39e/v7+atq0qT7//HN5eHiY9ZMmTZKTk5M6deqky5cvq3nz5oqKipKjo6NZs2DBAg0ePNicBSQsLExTp0693fMEAAAAAAAWV6CQwjCMm253c3PT6tWr/3Q/JUqU0JQpUzRlypQb1nh5eWn+/PkFaR4AAAAAALiL3dbAmQAAAAAAAIWNkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLKFBIERkZqXr16snDw0M+Pj568skndfjw4Tw1hmFo9OjRCggIkJubm5o0aaKDBw/mqUlPT9egQYPk7e2tUqVKKSwsTPHx8XlqkpOTFR4eLrvdLrvdrvDwcJ0/f/72zhIAAAAAAFhegUKKTZs26aWXXtL27du1du1aZWVlKTQ0VBcvXjRrJkyYoA8//FBTp07Vrl275Ofnp5YtW+rChQtmTUREhJYuXaro6Ght2bJFaWlpatu2rbKzs82arl27KjY2VjExMYqJiVFsbKzCw8ML4ZQBAAAAAIAVORWkOCYmJs/r2bNny8fHR3v27FGjRo1kGIYmT56sN954Qx06dJAkzZkzR76+vlq4cKFeeOEFpaSkaObMmZo3b55atGghSZo/f74CAwO1bt06tWrVSocOHVJMTIy2b9+u+vXrS5I+/fRThYSE6PDhw6pWrVphnDsAAAAAALCQvzQmRUpKiiTJy8tLkhQXF6fExESFhoaaNa6urmrcuLG2bt0qSdqzZ48yMzPz1AQEBKhGjRpmzbZt22S3282AQpIaNGggu91u1lwrPT1dqampeRYAAAAAAHD3uO2QwjAMDRkyRI899phq1KghSUpMTJQk+fr65qn19fU1tyUmJsrFxUVlypS5aY2Pj0++Y/r4+Jg114qMjDTHr7Db7QoMDLzdUwMAAAAAAEXgtkOKgQMHat++ffrss8/ybbPZbHleG4aRb921rq25Xv3N9jNy5EilpKSYy4kTJ27lNAAAAAAAgEXcVkgxaNAgffXVV9qwYYPKly9vrvfz85OkfL0dkpKSzN4Vfn5+ysjIUHJy8k1rTp06le+4p0+fztdLI5erq6s8PT3zLAAAAAAA4O5RoJDCMAwNHDhQS5Ys0fr161WpUqU82ytVqiQ/Pz+tXbvWXJeRkaFNmzapYcOGkqQ6derI2dk5T01CQoIOHDhg1oSEhCglJUU7d+40a3bs2KGUlBSzBgAAAAAAFC8Fmt3jpZde0sKFC7V8+XJ5eHiYPSbsdrvc3Nxks9kUERGhcePGqUqVKqpSpYrGjRunkiVLqmvXrmZt7969NXToUJUtW1ZeXl4aNmyYatasac72ERwcrNatW6tv376aMWOGJKlfv35q27YtM3sAAAAAAFBMFSikmD59uiSpSZMmedbPnj1bPXv2lCSNGDFCly9f1oABA5ScnKz69etrzZo18vDwMOsnTZokJycnderUSZcvX1bz5s0VFRUlR0dHs2bBggUaPHiwOQtIWFiYpk6dejvnCAAAAAAA7gI2wzCMom7EnZCamiq73a6UlJS7bnyKiq+tKOomALCAY+OfKOomFDmuhwBycU3kmgjgD3fbNbEgf5/f9uweAAAAAAAAhYmQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUUOKTYvHmz2rVrp4CAANlsNi1btizP9p49e8pms+VZGjRokKcmPT1dgwYNkre3t0qVKqWwsDDFx8fnqUlOTlZ4eLjsdrvsdrvCw8N1/vz5Ap8gAAAAAAC4OxQ4pLh48aJq166tqVOn3rCmdevWSkhIMJeVK1fm2R4REaGlS5cqOjpaW7ZsUVpamtq2bavs7GyzpmvXroqNjVVMTIxiYmIUGxur8PDwgjYXAAAAAADcJZwK+oY2bdqoTZs2N61xdXWVn5/fdbelpKRo5syZmjdvnlq0aCFJmj9/vgIDA7Vu3Tq1atVKhw4dUkxMjLZv36769etLkj799FOFhITo8OHDqlatWkGbDQAAAAAALO6OjEmxceNG+fj4qGrVqurbt6+SkpLMbXv27FFmZqZCQ0PNdQEBAapRo4a2bt0qSdq2bZvsdrsZUEhSgwYNZLfbzRoAAAAAAFC8FLgnxZ9p06aNnnnmGQUFBSkuLk5vvfWWmjVrpj179sjV1VWJiYlycXFRmTJl8rzP19dXiYmJkqTExET5+Pjk27ePj49Zc6309HSlp6ebr1NTUwvxrAAAAAAAwJ1W6CFF586dzZ9r1KihunXrKigoSCtWrFCHDh1u+D7DMGSz2czXV/98o5qrRUZG6p133vkLLQcAAAAAAEXpjk9B6u/vr6CgIB05ckSS5Ofnp4yMDCUnJ+epS0pKkq+vr1lz6tSpfPs6ffq0WXOtkSNHKiUlxVxOnDhRyGcCAAAAAADupDseUpw9e1YnTpyQv7+/JKlOnTpydnbW2rVrzZqEhAQdOHBADRs2lCSFhIQoJSVFO3fuNGt27NihlJQUs+Zarq6u8vT0zLMAAAAAAIC7R4Ef90hLS9PPP/9svo6Li1NsbKy8vLzk5eWl0aNH6+mnn5a/v7+OHTum119/Xd7e3nrqqackSXa7Xb1799bQoUNVtmxZeXl5adiwYapZs6Y520dwcLBat26tvn37asaMGZKkfv36qW3btszsAQAAAABAMVXgkGL37t1q2rSp+XrIkCGSpB49emj69Onav3+/5s6dq/Pnz8vf319NmzbV559/Lg8PD/M9kyZNkpOTkzp16qTLly+refPmioqKkqOjo1mzYMECDR482JwFJCwsTFOnTr3tEwUAAAAAANZW4JCiSZMmMgzjhttXr179p/soUaKEpkyZoilTptywxsvLS/Pnzy9o8wAAAAAAwF3qjo9JAQAAAAAAcCsIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALCEAocUmzdvVrt27RQQECCbzaZly5bl2W4YhkaPHq2AgAC5ubmpSZMmOnjwYJ6a9PR0DRo0SN7e3ipVqpTCwsIUHx+fpyY5OVnh4eGy2+2y2+0KDw/X+fPnC3yCAAAAAADg7lDgkOLixYuqXbu2pk6det3tEyZM0IcffqipU6dq165d8vPzU8uWLXXhwgWzJiIiQkuXLlV0dLS2bNmitLQ0tW3bVtnZ2WZN165dFRsbq5iYGMXExCg2Nlbh4eG3cYoAAAAAAOBu4FTQN7Rp00Zt2rS57jbDMDR58mS98cYb6tChgyRpzpw58vX11cKFC/XCCy8oJSVFM2fO1Lx589SiRQtJ0vz58xUYGKh169apVatWOnTokGJiYrR9+3bVr19fkvTpp58qJCREhw8fVrVq1W73fAEAAAAAgEUV6pgUcXFxSkxMVGhoqLnO1dVVjRs31tatWyVJe/bsUWZmZp6agIAA1ahRw6zZtm2b7Ha7GVBIUoMGDWS3282aa6Wnpys1NTXPAgAAAAAA7h6FGlIkJiZKknx9ffOs9/X1NbclJibKxcVFZcqUuWmNj49Pvv37+PiYNdeKjIw0x6+w2+0KDAz8y+cDAAAAAAD+d+7I7B42my3Pa8Mw8q271rU116u/2X5GjhyplJQUczlx4sRttBwAAAAAABSVQg0p/Pz8JClfb4ekpCSzd4Wfn58yMjKUnJx805pTp07l2//p06fz9dLI5erqKk9PzzwLAAAAAAC4exRqSFGpUiX5+flp7dq15rqMjAxt2rRJDRs2lCTVqVNHzs7OeWoSEhJ04MABsyYkJEQpKSnauXOnWbNjxw6lpKSYNQAAAAAAoHgp8OweaWlp+vnnn83XcXFxio2NlZeXlypUqKCIiAiNGzdOVapUUZUqVTRu3DiVLFlSXbt2lSTZ7Xb17t1bQ4cOVdmyZeXl5aVhw4apZs2a5mwfwcHBat26tfr27asZM2ZIkvr166e2bdsyswcAAAAAAMVUgUOK3bt3q2nTpubrIUOGSJJ69OihqKgojRgxQpcvX9aAAQOUnJys+vXra82aNfLw8DDfM2nSJDk5OalTp066fPmymjdvrqioKDk6Opo1CxYs0ODBg81ZQMLCwjR16tTbPlEAAAAAAGBtNsMwjKJuxJ2Qmpoqu92ulJSUu258ioqvrSjqJgCwgGPjnyjqJhQ5rocAcnFN5JoI4A932zWxIH+f35HZPQAAAAAAAAqKkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlFHpIMXr0aNlstjyLn5+fud0wDI0ePVoBAQFyc3NTkyZNdPDgwTz7SE9P16BBg+Tt7a1SpUopLCxM8fHxhd1UAAAAAABgIXekJ8VDDz2khIQEc9m/f7+5bcKECfrwww81depU7dq1S35+fmrZsqUuXLhg1kRERGjp0qWKjo7Wli1blJaWprZt2yo7O/tONBcAAAAAAFiA0x3ZqZNTnt4TuQzD0OTJk/XGG2+oQ4cOkqQ5c+bI19dXCxcu1AsvvKCUlBTNnDlT8+bNU4sWLSRJ8+fPV2BgoNatW6dWrVrdiSYDAAAAAIAidkd6Uhw5ckQBAQGqVKmSnn32Wf3yyy+SpLi4OCUmJio0NNSsdXV1VePGjbV161ZJ0p49e5SZmZmnJiAgQDVq1DBrAAAAAABA8VPoPSnq16+vuXPnqmrVqjp16pTGjBmjhg0b6uDBg0pMTJQk+fr65nmPr6+vfv31V0lSYmKiXFxcVKZMmXw1ue+/nvT0dKWnp5uvU1NTC+uUAAAAAADA/0ChhxRt2rQxf65Zs6ZCQkJ0//33a86cOWrQoIEkyWaz5XmPYRj51l3rz2oiIyP1zjvv/IWWAwAAAACAonTHpyAtVaqUatasqSNHjpjjVFzbIyIpKcnsXeHn56eMjAwlJyffsOZ6Ro4cqZSUFHM5ceJEIZ8JAAAAAAC4k+54SJGenq5Dhw7J399flSpVkp+fn9auXWtuz8jI0KZNm9SwYUNJUp06deTs7JynJiEhQQcOHDBrrsfV1VWenp55FgAAAAAAcPco9Mc9hg0bpnbt2qlChQpKSkrSmDFjlJqaqh49eshmsykiIkLjxo1TlSpVVKVKFY0bN04lS5ZU165dJUl2u129e/fW0KFDVbZsWXl5eWnYsGGqWbOmOdsHAAAAAAAofgo9pIiPj1eXLl105swZlStXTg0aNND27dsVFBQkSRoxYoQuX76sAQMGKDk5WfXr19eaNWvk4eFh7mPSpElycnJSp06ddPnyZTVv3lxRUVFydHQs7OYCAAAAAACLKPSQIjo6+qbbbTabRo8erdGjR9+wpkSJEpoyZYqmTJlSyK0DAAAAAABWdcfHpAAAAAAAALgVhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwBEIKAAAAAABgCYQUAAAAAADAEggpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAgAAAAAAWAIhBQAAAAAAsARCCgAAAAAAYAmEFAAAAAAAwBIIKQAAAAAAgCUQUgAAAAAAAEsgpAAAAAAAAJZASAEAAAAAACyBkAIAAAAAAFgCIQUAAAAAALAEQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYguVDimnTpqlSpUoqUaKE6tSpo++++66omwQAAAAAAO4AS4cUn3/+uSIiIvTGG29o7969+sc//qE2bdro+PHjRd00AAAAAABQyCwdUnz44Yfq3bu3+vTpo+DgYE2ePFmBgYGaPn16UTcNAAAAAAAUMqeibsCNZGRkaM+ePXrttdfyrA8NDdXWrVvz1aenpys9Pd18nZKSIklKTU29sw29A3LSLxV1EwBYwN14/SpsXA8B5OKayDURwB/utmtibnsNw/jTWsuGFGfOnFF2drZ8fX3zrPf19VViYmK++sjISL3zzjv51gcGBt6xNgLAnWSfXNQtAADr4JoIAH+4W6+JFy5ckN1uv2mNZUOKXDabLc9rwzDyrZOkkSNHasiQIebrnJwcnTt3TmXLlr1uPWBlqampCgwM1IkTJ+Tp6VnUzQGAIsP1EAD+wDURdyvDMHThwgUFBAT8aa1lQwpvb285Ojrm6zWRlJSUr3eFJLm6usrV1TXPutKlS9/JJgJ3nKenJ/8AAYC4HgLA1bgm4m70Zz0ocll24EwXFxfVqVNHa9euzbN+7dq1atiwYRG1CgAAAAAA3CmW7UkhSUOGDFF4eLjq1q2rkJAQ/fvf/9bx48fVv3//om4aAAAAAAAoZJYOKTp37qyzZ8/q3XffVUJCgmrUqKGVK1cqKCioqJsG3FGurq4aNWpUvkeYAOBew/UQAP7ANRH3AptxK3OAAAAAAAAA3GGWHZMCAAAAAADcWwgpAAAAAACAJRBSAAAAAAAASyCkAAAAAAAAlkBIAQAAAAAALIGQAriDcnJyzJ+zs7MlSZcuXSqq5gCAZWRmZkrKe50EAAAgpADuIAcHBx07dkwbNmyQo6OjvvjiC40dO1YXL14s6qYBQJGJjo7Wc889pzNnzsjBwYGgAgAAmJyKugFAcXblyhWNGzdOa9euVffu3fXee+8pKipKpUqVKuqmAUCRiIuLU//+/ZWRkSEHBwdNnjxZvr6+ysnJkYMD350AAHCvsxmGYRR1I4Di7ODBg+rXr5+2bdumESNGaPz48crJyZHNZpPNZivq5gHA/1RiYqLat28vSapUqZKysrI0bdo0+fj4EFQAuOcYhiGbzaa4uDhlZWUpNTVVderUKepmAUWKOwHgDsntvhwQECBXV1f97W9/U0xMjNasWWPehJMRAriXGIYhPz8/vfLKK0pKSlKlSpV07tw5vfTSSzp9+jSPfgC4p+QGFEuXLlXbtm3VoUMHPfHEE+revbuOHj1a1M0DigwhBXAHGIYhBwcHHTlyRBkZGfr88881e/ZsPfjggxo6dKjWrFmTpxdFSkpKEbYWAO6sjIwMSX+Etw0bNtRjjz2mRx99VL1799aJEycIKgDcc2w2mzZs2KDw8HC98sor2rp1q/7zn/9o/vz52rt3b1E3DygyhBRAIctNxZcvX64WLVpo2bJlcnd3V61atTR48GDVrFlTw4cPN4OKsWPHauLEieZI9wBQnHzxxRd6+umntXXrVjOQrVChgkqWLKn3339f3bp108CBA/Xbb79p4MCBZlBBTzMAxc31vpTatGmTunfvrj59+igpKUmvvPKK+vbtq44dOxZBCwFrIKQACpnNZtPXX3+trl27avjw4WrdurXc3NwkSQ0aNNDQoUNVs2ZNderUSY8//rhGjRqlJ598Us7OzkXccgAoXIcPH9aAAQO0YsUKPf/88xoxYoTGjBkjSXr//ffl6empL7/8Ut26dVOPHj106tQpPfvss0pOTmbMHgDFysyZM1WzZk398ssv5jrDMLRjxw6VK1dO6enpaty4sZo1a6ZPPvlEkjR16lQtWbKkqJoMFBlCCqCQpaWlafLkyRo+fLgGDhwoPz8/JSUl6d///re2bNmiGjVqaPz48Ro/frwqV66sAwcO6JFHHinqZgNAofP29tagQYPUvHlz+fr6qnHjxlq8eLFatmyp0aNHy8HBQbt27ZLNZlPfvn3VoUMHVatWTXa7vaibDgCF6oknnlDp0qXVsWNHM6iw2Wxq37691q9fr8DAQIWFhemTTz6RzWaTYRiKjY3Vhg0blJ6eXsStB/63mN0DKGTJyclq1KiRBgwYoHbt2mnq1KnasWOHdu/eraCgIL3wwgsaNGiQpD8eDQGA4urUqVOaPXu2Fi9erMcff1zvvfeeZs2apS1btigqKkrlypXTDz/8oLJly0r647rITB8AipvTp0+rVatWysrK0tKlS3X//fdr69atevnll3Xp0iXNmjVL9evXV1pamsaPH6+oqCitX79eVatWLeqmA/9ThBTAHfDSSy9pzpw5cnZ2VrNmzdS6dWv17t1bYWFhKlOmjObNm1fUTQSAO+K///2vTp48KS8vLwUHB8tutyspKUmzZ8/WrFmz1KlTJ7333nuSpK+++krVq1dX1apV84QSBLgAiqukpCS1bt1amZmZ+uqrr1SpUiUtXrxYH330kRITE3XffffJ2dlZBw8e1MqVK/W3v/2tqJsM/M8RUgB/Qe6N9OHDh5WcnKxLly6pWbNmkqQVK1YoIyNDbdu2lc1mk5OTk/r16ycnJyf961//kqOjIzfhAIqVWbNmacyYMcrOzparq6u6du2qV199VW5ubjp79qz+85//aM6cOQoNDdXkyZPN9xFKACiObnRtO336tFq2bKmsrCx98803qlixonbv3q0DBw5ox44devjhh9WiRQvdf//9RdBqoOgRUgC3Kfcfni+++EJDhgyRzWZTRkaG/Pz8NHfuXNWsWdOsTUhI0Mcff6ypU6dq69atevDBB4uw5QBQ+P79739r4MCBmj17tpo0aaKJEycqJiZGsbGxcnFxkfT7ox9RUVGaP3++WrVqpX/+859F3GoAKHxZWVlycnIy7xUPHjyo+Ph4lStXToGBgSpXrpzOnDmjFi1aKCsrS19//bUqVapU1M0GLIOQAvgLtm/frtDQUH300UeqX7++DMNQ//79FR8frxUrVujBBx/Uhg0bNGHCBB09elSLFi3Sww8/XNTNBoBCNXPmTL344otavHix2rdvL0mKi4vTs88+q+7du+vixYtq3769qlWrpqSkJM2ZM0cffPCB3nrrLXOMHgAoDiIjI+Xq6qp+/frJ3d1dS5YsUffu3eXv76/4+Hg1adJEPXv2VOfOnc2gwsHBQdHR0Yw9Afx/hBTAX/Dpp59q7ty5WrdunVxdXc31DRs2lGEY2rZtm65cuaKVK1fqkUceUcWKFYuusQBwB6SlpemRRx5RZmamDh48qJIlS0qSHn/8ce3du1dBQUE6d+6cjh07pu3bt+uRRx7RqVOntG7dOj377LNydHQs4jMAgMIzdOhQTZo0SR9//LGaNm2qTp066cUXX1SnTp20d+9eRUVF6ccff9Srr76qZ555RqdPn9bf//533XfffdqwYQNT0gMipAD+ktGjR2v27Nn69ddfJUlXrlxRiRIltH37dj399NP65ptvGPAIQLF38OBBPfHEE3rwwQe1ZMkShYeH69ChQ/ryyy8VFBSko0eP6tlnn5Wfn5++/vprlShRwnxvdnY2QQWAYmX06NEaN26c3nnnHR04cEAzZsyQu7u7pN8HF46MjNSVK1c0d+5ceXp66syZM7pw4QKPfAD/H3N7AX9B586dlZWVpbFjx0qSeePt6OgoFxcX8zlsAChusrKylJWVJUl66KGHtGrVKu3bt09lypTRoUOHtHLlSlWrVk0lSpRQcHCwqlWrJk9PzzwBhSQCCgDFRk5OjqTfQ4pXX31Vb7zxhlavXq1Tp06ZNbVr19Zzzz2nlStXKj4+XpLk7e1NQAFchZACuAW5HY6OHj2q7du368cff1RKSoqCg4PVo0cPff311xozZowkKSUlRd98841KlCihcuXKFWWzAeCOiImJ0ciRI9WxY0edO3dOhmEoODhY69atU+XKlWW322W32836rKwsJScnM1I9gGItdxplSXrvvff0/vvv69y5c4qOjlZycrK5rWbNmqpQoYLOnz9fBK0ErM+pqBsAWF3uyMxLlizRoEGDVLJkSZ08eVLNmjXT0KFD9eabb8rBwUHTpk3Tv/71LwUGBio+Pl6rVq2Sj49PUTcfAApVVFSU3nvvPfXv31/Vq1eXl5eXpN8fd6tevbq++OILtWjRQs8884wWLVqk0qVL66mnntLp06c1btw4SUw5CqB4yb2mnTx5UhkZGSpfvrycnZ01fPhwpaam6u2331ZWVpaeeeYZlStXTtOmTVNqaiq9J4AbYEwK4Bbs2LFDLVu2VGRkpNq3b6/Y2FjNmzdPR48e1cSJE9W4cWMdP35cy5YtU0BAgOrUqcM/PACKnejoaPXq1Uv/+c9/1L59e5UqVUqS9MYbb+iBBx5Q586dVbJkSR06dEihoaGqUaOGsrKydOLECe3fv1/Ozs6MQQGgWPryyy/1+uuv6+zZs2rZsqWee+45PfHEE5Kkt956S2PHjpWHh4eeeOIJ/fTTT/r0008Ztwy4AUIK4CZyk/GJEyfqm2++0YYNG8xte/bs0dixY+Xg4KC5c+eaI9oDQHF08uRJdezYUR06dNDw4cPN9WFhYfrmm29UsmRJTZ8+XR07dpSbm5sOHTqkRx99VF5eXjp06JCcnZ2VlZUlJyc6cQIoXn755Re1adNGAwcOVLly5fTRRx/J3d1dPXv2VLdu3SRJEydO1PDhw/Xxxx+rc+fOZi80APlxpwDcRG53ZGdnZyUlJens2bMqW7asJKlOnTrq0qWLunfvrqSkJKYXBVCsnT17Vr/++qsee+wxc938+fP1448/6sKFC3rjjTfUv39/ZWdn65lnnlFwcLBiY2N13333ydHRkYACQLGR+x1v7n1iyZIl9Y9//EP9+/eXs7Oz/v73v2vQoEGaNWuWJKlbt24aOnSoLl68qKZNmxJQAH+CgTOBWxAUFKSTJ09q/fr1urrz0YMPPqiKFSvq8uXLRdg6ALjzfvvtN50/f17e3t7murCwMG3btk2lSpXS5MmT1bVrV/Xv31/Hjx+XJFWoUEGOjo7Kzs4moABQrNhsNq1Zs0Z9+vTRkCFDlJycLGdnZ0lS5cqV9dFHH8nV1VVz587VzJkzJUlvv/22qlevXpTNBu4KhBTAVTIzMyVJBw4c0JYtW7Rx40ZJUvv27RUeHq7nn39eixYtUnx8vDIzMxUVFaXs7Gxm8QBQLGVnZ5s/e3l56cqVK9q+fbuk379J9PT0VNmyZc2pSDt37qxHH3003+NvjEEBoDix2Wxav369WrdureTkZG3ZskXr1q3T5MmTzZoHHnhAU6ZM0cWLF/X1118rNTW16BoM3GUYkwL3vBkzZuiXX37R+++/L+n3geFeeukllShRQtnZ2QoKCtLcuXNVrVo1DR48WAsXLpS7u7v8/Px09OhRrVmzhoGPABQ76enpcnV1lSTt3btXtWrVUseOHfX9999rw4YNeuihh/IMgnn58mVz5PpZs2YxeweAYuvnn3/WunXrlJOTowEDBiguLk5jxozR4cOH1aVLF7300ktmbVxcnJycnBQYGFiELQbuLoQUuKelpaXpnXfe0bJly9SzZ0+9/PLLatKkiQYMGKCQkBBlZGSoT58+On/+vFavXq3KlStr7dq1SkxMVFZWlpo2bcpYFACKnXXr1unDDz/UypUrFRERoe+//15r165VbGysXnrpJZ0+fVqff/656tWrJ3d3d8XGxurVV1/Vb7/9pr1798rJyYlpRgEUSz///LOeeuopnTt3TpMmTVKnTp0kSUePHlVkZKQOHjyoHj16qH///kXcUuDuRUiBe97Jkyc1c+ZMLVq0SHXr1tX58+cVFRWl0qVLS/q9S3PdunXl5uamLVu2FG1jAeAOy8nJ0bx58zRt2jRduHBBiYmJ2rlzpx544AEZhqHVq1crMjJS3333napVq6aMjAx5eHiodOnSWrt2LdOMAijWjh8/rilTpigqKkrdunXL84hHbs/czZs3a+jQoerTp0/RNRS4ixFS4J6Tk5MjB4ffh2PJ/abvxIkTmjlzpqKjo3XlyhUdO3ZM0u/dl93c3LR161Z17NhRX331lerWrVuErQeA/43OnTtr8eLFatq0qb799ts82y5cuKDFixfrl19+kYODg/7+97+rTZs2zOIB4J5w4sQJffLJJ1qwYIH69eun119/3dx25MgRTZkyRUOGDKG3LXCbuIvAPSU3oIiPj9emTZt06NAhjRgxQoGBgXrhhRckSePHj9fw4cP1wQcfyM3NTZLk6uoqBwcHvhkEUGzlhrbZ2dnKyMhQs2bN9Le//U0rVqxQ+/btNX/+fHl4eCgzM1MeHh7q1atXvn0wiweA4iT3unjkyBElJCTI1dVVNWvWVGBgoPr27Subzaa5c+dKkhlUVKlSRR9++CHXQuAv4NODe0ZuQHHgwAH17NlTDz/8sPz8/OTp6SlJ8vf3V79+/SRJc+fOVU5OjiZMmKAzZ85o6dKlstls8vX1LcpTAIA74urHM3JyclSiRAkzuPXz89Mnn3yi5557TgsWLJC7u7skadOmTapbt65KlSpl7ocgF0BxkRtQLF26VK+99prS09Pl4+OjcuXKaeHChapYsaJ69+4tSfrss890+fJlvffee5JEQAH8RUxBinuCYRhycHDQDz/8oEaNGqlFixYaNWqUxowZI0lauHChfvrpJwUEBKhPnz7q3r27pk6dqqCgIA0cOFDr16/XsmXLFBAQUMRnAgCFZ+vWrZL+CBciIyPVtm1bhYaGatGiRZKkbt26acCAATp9+rQ6duyoQ4cOqVWrVho/fny+qUYBoLiw2Wxau3atevbsqYiICP3www8aMGCAVq1apZYtWyo5OVmVKlVSnz591LJlS61Zs0Znz54t6mYDxQJjUuCekZycrPbt26t69er697//ba4fP368Xn/9dXl5eem7775TcHCwEhIS9J///EfTpk1Tp06dNGbMGHl4eBRh6wGgcM2bN089evRQdHS0OnXqpMjISE2aNEndu3fX8ePH9cUXX+j999/X8OHDlZmZqaVLl+rDDz/U8ePHVblyZW3YsEHOzs5FfRoAcEckJydrwIABql27tl577TWdOnVK9erVU506dfTLL7/I2dlZ3377rex2u3799VeVLFlS5cqVK+pmA8UCfZFQ7OV21zt+/LjOnTunLl26mNu+/PJLjR8/XnPnztXixYvVpEkTbdy4UcHBwerevbtcXFzUqVMnAgoAxU779u01YsQIdevWTY6OjnJxcdFnn32m5s2bKysrS//4xz8UEREhwzA0YsQIdezYUaGhoTpy5Ijq1KkjBwcHBskEUGyVKVNGTz31lCpWrKizZ88qNDRUTzzxhKZPn67JkydryJAhqlu3rnbu3KmgoKCibi5QrHBngWIrdwyKrKwsOTs769ChQzp+/Ljuv/9+s8bX11ffffedatasqZYtW6pPnz5mQh4UFKRhw4bxjDWAYsnT01NvvvmmDMNQp06d5O3trYULF0r6/XnqQYMGyWazKSIiQjabTcOHD1fp0qVVr149SQySCaB4yf1S6/Dhw0pPT1etWrXUqVMnSdKiRYvk7e2tt99+W5JUqVIlNWnSRB4eHjp37pzKlClTlE0Hih3GpECx5eDgoJ9//tkcd8Ld3V1paWk6fvy4WfPYY4+pZs2akn4PLLp06aJq1aopOztbEoPAASh+cnJyzJ/d3d315ptv6p133tHp06d1+PBhSb/frEvSwIED9a9//UuvvvqqGWDk4voIoLi4epDMdu3aaf369Tp58qS5PS4uTv/9739VtmxZSdL27dv14IMP6rPPPsvz5ReAwsGYFCjW3nrrLS1cuFBHjx5VcnKyWrZsqZycHC1btkwVKlRQRkaGXFxczF4Xr7zyio4fP645c+aYI9gDQHGReyMu/T5gcIsWLeTj46PU1FRFRkZqwoQJWrhwoTp37pznfUuWLFFYWBg9JwAUWytXrtQzzzyj8ePHKzw8XKVLlza3HTx4UF26dFFWVpaqVaumNWvWaOfOnXrooYeKrsFAMUZPChRLudnbo48+KldXV125ckVlypRReHi4kpKS1KdPH8XHx8vFxUXS74MjjRw5UnPmzNG7775LQAGg2MnJyTEDisTERD333HMaPHiwzpw5I09PT73xxhsaNmyYunbtqs8//1zSH9fSDh06yMnJSVlZWUXWfgC4EwzD0IULFzRp0iQNHz5cgwYNkrOzs44dO6bp06dr3rx5euihh/Svf/1Ljz32mLy9vQkogDuMr0RQbOT2hpBk3ohXqlRJx44d03fffaeWLVvq5Zdf1vnz5zVz5kzVqFFDvXr1UlJSklJTU7Vnzx59++23/KMDoNjJnYZZkt5++20lJSWpcuXKWrRokdLS0jRnzhyVLVtWb731lmw2m8LDw3Xp0iU9//zzefZDTwoAxY3NZlOpUqXk5uamlJQUHT16VFOmTNG+ffv0888/Ky0tTfv379eECRPUpEkTBgwG/gfoSYFiw8HBQceOHdPs2bMVFxenxMREVaxYUVWqVNHly5fNulGjRmnGjBnq3LmzNm/erF9//VV/+9vftGnTJv3tb38rwjMAgDsjN7j95z//qalTp6pbt2767LPP9OWXX2r37t167rnndPbsWXOMit69e2vWrFlF3GoAuDOufdrdMAxVqVJF27ZtU7Vq1RQfH6/nn39esbGxev7553Xs2DHzPQQUwJ3HmBQoFgzDUGZmpp5++mnt3btXDg4Ounz5skJDQ/XZZ5+pffv2+uCDD+Tg4KDKlSub78vMzJSzs3Oe57QBoDjYvHmzGjZsaN5QG4ahbt26ydvbW//617/Mul27dunxxx/XP/7xD82YMUPlypXTpUuXVKJECbP3BQAUF7n3fHv27NGRI0fk7u6utm3bKisrS7GxsTp9+rTatGlj1j3//PPKycnRzJkzCSiA/xE+aSgWbDabXFxctHDhQnl4eGjv3r368ccfFR8fr9jYWC1fvlz/93//p8zMTD300EPy9/fX3//+d4WEhKhOnTpF3XwAKFSjR4/W2rVrtWXLFnNdTk6OTp48qStXrpjrsrOzVa9ePQ0YMEDvvfeeHB0d9dlnn6lkyZIyDIMAF0CxY7PZtGzZMnXu3FnBwcHat2+funbtqtGjR6tu3bpmXUJCgiZPnqzly5fru+++I6AA/ofoSYFi5Xo31B988IFiY2M1fPhwnT17Vhs3btSePXuUnJysuXPnqkqVKkXUWgC4c3Kfmz58+LCCgoJUokQJffbZZxo+fLgmTJigrl27mrWffvqpvv/+e61atUpPPvmkZsyYUYQtB4DCcfV4Zbn3iKdPn1a3bt3UpUsXPfPMM9q/f7/at2+vxo0ba9SoUapRo4ZiYmI0a9YsHThwQAsXLtTDDz9ctCcC3GMIKVDsffHFF+rbt6/279+v8uXLm+svXryoUqVKFWHLAKDw5d6UG4ah5cuXq0OHDlq8eLGefPJJ/fbbbxo1apR++ukn9evXT927d9eZM2fUq1cvtWzZUqVKldJbb72lDRs2qGrVqkV9KgBw23KvhUeOHNGJEyfUrFkzrV69Wl988YVSU1P10Ucfyc/PT9Lvj721a9dOjRo10vjx41WxYkV9/fXXeuSRRxQYGFjEZwLce3jYFMWaYRiqUaOG3N3dzS7O2dnZkqSSJUsWZdMA4I64epajJ598Up06dVK/fv301VdfKTAwUEOGDFGNGjU0ePBgVa5cWX//+98VFxenQYMGydvbW25ubrLb7UV8FgBw+3IDitjYWD3yyCM6fPiwuX7mzJn6+uuvlZCQIOn3e8V69erpm2++0bZt29SvXz/9+uuvat++PQEFUEQIKVCs2Ww2Va9eXaVKldLGjRslSY6OjuY2ACguzp49m+d1VlaWJCk6OlqtW7dWjx49tHTpUtWoUUMffPCBNm/erIEDB2rMmDHau3evJGn9+vUKDAyUq6vr/7z9AFAYcgOK//73v3r00Uc1cOBAvfjiizIMQ23atNH333+vjIwMTZkyRYmJibLZbDIMQ3Xr1tXixYt14sQJOTs7F/VpAPc0RoBBsZb7/KGbm5vi4uKKujkAcEd89913evvtt/XOO++oUaNGkn6fJi87O1uOjo5asGCBunXrph49ekiS2rRpo1q1aqlWrVqSpMOHD2vatGmaM2eONm/erNKlSxfVqQDAbcsNKPbt26eGDRsqIiJCY8eOlfT7l1MrV65U06ZNFRMTo1atWsnFxUWjR4+Wn5+fDMNQgwYNtG/fPoJaoIjRkwLFWm5viX79+qlLly5F3BoAuDN8fHxkGIYmTJig77//3lzv6OhoPuK2YMEChYWFqW/fvlq6dKkyMjIk/T4V8+bNm3Xy5Elt3rzZDC4A4G7j4OCgEydOqHnz5mrbtq0ZUEjSmDFj1K9fPx09elQtWrTQypUr9emnn2rMmDH67bffzHtGFxeXomo+gP+PgTNxT2AaPQDF3ZEjRzR48GAZhqG33npLjz76qKTfr385OTnmo24VKlRQvXr19OWXX5rvzczM1OXLl+Xp6VkkbQeAwnLs2DF16tRJ/v7+GjFihB599FGNHz9eEydO1Lx589S6dWuzl9nq1avVpk0bDR48WBMnTjSvkwCKFiEFAADFxNVBxZtvvqnHHnvM3BYfH68XX3xRDz74oMaNG2fejBPiAihucq+FLi4u8vX11bJlyzR//nyFhoZK+uO6d+nSJf38889ydnZWcHBwEbcaQC5CCgAAipHr9ag4deqUOnXqpOPHj+unn36Ss7Oz+U0iABRHP/30kwYOHKgtW7bovffe09ChQ5X7Z4/NZtObb76pWbNm6ciRI0xJD1gMIQUAAMVMblBhs9n04osvasqUKYqPj9d///tfOTs7KysrS05OjJ0NoHg7evSoBgwYIEdHR40cOVL/+Mc/JElvv/22PvjgA3333XeqW7duEbcSwLUIKQAAKIaOHDmiiIgIrVq1StWrVyegAHBPurp3WWRkpNauXatRo0Zpy5YtqlOnTlE3D8B1EFIAAFBM/fjjj5o2bZo+/PBDOTk5EVAAuCcdOXJEQ4YM0c6dO5WcnKxt27YRUAAWRkgBAMA9gIACwL3s8OHDGjFihMaNG6eHHnqoqJsD4CYIKQAAAAAUe5mZmXJ2di7qZgD4E4QUAAAAAADAEhyKugEAAAAAAAASIQUAAAAAALAIQgoAAAAAAGAJhBQAAAAAAMASCCkAAAAAAIAlEFIAAAAAAABLIKQAAAAAAACWQEgBAAAAAAAsgZACAAAAAABYAiEFAAAAAACwhP8HUMAL/S7B3vwAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,3))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"MSE\")\n",
        "ejeX = ['XGboost', 'LightGBM', 'Ensamble']\n",
        "ejeY = [mse, mse_lgb_rfe, mse_stack]\n",
        "ax.bar(ejeX,ejeY)\n",
        "def addlabels(x, y, plotP):\n",
        "    for i in range(len(x)):\n",
        "        plotP.text(i, y[i], f'{y[i]:.4f}')\n",
        "\n",
        "addlabels(ejeX, ejeY, plt)\n",
        "ax.set_xticks(range(len(ejeX)))\n",
        "ax.set_xticklabels(ejeX, rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(10,3))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"RMSE\")\n",
        "ejeX = ['XGboost', 'LightGBM', 'Ensamble']\n",
        "ejeY = [rmse, rmse_lgb_rfe, rmse_stack]\n",
        "ax.bar(ejeX,ejeY)\n",
        "def addlabels(x, y, plotP):\n",
        "    for i in range(len(x)):\n",
        "        plotP.text(i, y[i], f'{y[i]:.4f}')\n",
        "\n",
        "addlabels(ejeX, ejeY, plt)\n",
        "ax.set_xticks(range(len(ejeX)))\n",
        "ax.set_xticklabels(ejeX, rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(10,3))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title(\"R2\")\n",
        "ejeX = ['XGboost', 'LightGBM', 'Ensamble']\n",
        "ejeY = [r2, r2LG, r2_stack]\n",
        "ax.bar(ejeX,ejeY)\n",
        "def addlabels(x, y, plotP):\n",
        "    for i in range(len(x)):\n",
        "        plotP.text(i, y[i], f'{y[i]:.4f}')\n",
        "\n",
        "addlabels(ejeX, ejeY, plt)\n",
        "ax.set_xticks(range(len(ejeX)))\n",
        "ax.set_xticklabels(ejeX, rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5354912d",
      "metadata": {
        "id": "5354912d"
      },
      "source": [
        "Basándonos en los resultados el modelo de ensamble (stacking) ha obtenido el mejor rendimiento tanto en términos de MSE (Mean Squared Error), RMSE (Root Mean Squared Error) como R², en comparación con los modelos individuales de XGBoost y LightGBM, algunas consideraciones:\n",
        "\n",
        "\n",
        "XGBoost mejora el rendimiento en comparacion con los modelos de prueba, esto sugiere que puede capturar mejor la complejidad de los datos y realizar predicciones más precisas.\n",
        "\n",
        "LightGBM tiene un rendimiento ligeramente mejor que XGBoost, con un RMSE menor y un R² ligeramente mayor. Esto puede deberse a su eficiencia y a la forma en que maneja las características categóricas tras la codificación one-hot.\n",
        "\n",
        "El modelo de ensamble ha superado a todos los modelos individuales, esto se debe a que el stacking aprovecha las fortalezas de cada modelo base, permitiendo que la regresión lineal como meta-modelo ajuste los pesos finales y realice predicciones que son el promedio ponderado de las predicciones de los modelos base, el resultado es un modelo que generaliza mejor a datos y ofrece predicciones más estables y precisas.\n",
        "\n",
        "\n",
        "Conclusiones:\n",
        "\n",
        "El modelo de ensamble proporciona el mejor rendimiento general al combinar las predicciones de múltiples modelos, lo que lleva a un mejor ajuste y una generalización más fuerte, la reducción en RMSE es particularmente significativa, ya que es una métrica que penaliza más los errores grandes, lo que indica que el modelo de ensamble es mejor para manejar las diferencias entre los valores de predicción y los valores reales. El aumento en el R² muestra que el modelo de ensamble puede explicar una mayor proporción de la varianza en los datos de prueba, lo que indica que se ajusta mejor a los datos sin caer en el sobreajuste,\n",
        "estos resultados demuestran la eficacia de combinar modelos con diferentes fortalezas y patrones de aprendizaje, lo que a menudo puede producir un modelo compuesto que es superior a cualquiera de sus componentes individuales.\n",
        "\n",
        "\n",
        "\n",
        "RMSE proporciona una medida de la magnitud del error en las mismas unidades que la variable de interés, en este caso, el precio del vehículo, para el mejor modelo(ensamble) la desviacion respecto al precio real es de 3399,49\n",
        "\n",
        "Un R² cercano a 1 indica que el modelo puede explicar muy bien la variabilidad de los precios de los vehículos basado en las características, en este caso el mejor modelo  (ensamble) 0,8995 que es cercano a 1, y se considera muy bueno (con posibilidad de mejorar)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2b1c1d",
      "metadata": {
        "id": "1f2b1c1d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
